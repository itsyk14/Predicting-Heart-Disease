{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
       "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          41\n",
       "sex           2\n",
       "cp            4\n",
       "trestbps     49\n",
       "chol        152\n",
       "fbs           2\n",
       "restecg       3\n",
       "thalach      91\n",
       "exang         2\n",
       "oldpeak      40\n",
       "slope         3\n",
       "ca            5\n",
       "thal          4\n",
       "target        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('target',axis=1)\n",
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (303,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking correlation between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098447</td>\n",
       "      <td>-0.068653</td>\n",
       "      <td>0.279351</td>\n",
       "      <td>0.213678</td>\n",
       "      <td>0.121308</td>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.398522</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.210013</td>\n",
       "      <td>-0.168814</td>\n",
       "      <td>0.276326</td>\n",
       "      <td>0.068001</td>\n",
       "      <td>-0.225439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.098447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.049353</td>\n",
       "      <td>-0.056769</td>\n",
       "      <td>-0.197912</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>-0.058196</td>\n",
       "      <td>-0.044020</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>-0.030711</td>\n",
       "      <td>0.118261</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>-0.280937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>-0.068653</td>\n",
       "      <td>-0.049353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.044421</td>\n",
       "      <td>0.295762</td>\n",
       "      <td>-0.394280</td>\n",
       "      <td>-0.149230</td>\n",
       "      <td>0.119717</td>\n",
       "      <td>-0.181053</td>\n",
       "      <td>-0.161736</td>\n",
       "      <td>0.433798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>0.279351</td>\n",
       "      <td>-0.056769</td>\n",
       "      <td>0.047608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123174</td>\n",
       "      <td>0.177531</td>\n",
       "      <td>-0.114103</td>\n",
       "      <td>-0.046698</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>-0.121475</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>-0.144931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>0.213678</td>\n",
       "      <td>-0.197912</td>\n",
       "      <td>-0.076904</td>\n",
       "      <td>0.123174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>-0.151040</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>0.067023</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>0.070511</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>-0.085239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>0.121308</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>0.177531</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.084189</td>\n",
       "      <td>-0.008567</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>-0.059894</td>\n",
       "      <td>0.137979</td>\n",
       "      <td>-0.032019</td>\n",
       "      <td>-0.028046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>-0.116211</td>\n",
       "      <td>-0.058196</td>\n",
       "      <td>0.044421</td>\n",
       "      <td>-0.114103</td>\n",
       "      <td>-0.151040</td>\n",
       "      <td>-0.084189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.044123</td>\n",
       "      <td>-0.070733</td>\n",
       "      <td>-0.058770</td>\n",
       "      <td>0.093045</td>\n",
       "      <td>-0.072042</td>\n",
       "      <td>-0.011981</td>\n",
       "      <td>0.137230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>-0.398522</td>\n",
       "      <td>-0.044020</td>\n",
       "      <td>0.295762</td>\n",
       "      <td>-0.046698</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>-0.008567</td>\n",
       "      <td>0.044123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.378812</td>\n",
       "      <td>-0.344187</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>-0.213177</td>\n",
       "      <td>-0.096439</td>\n",
       "      <td>0.421741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>-0.394280</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>0.067023</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>-0.070733</td>\n",
       "      <td>-0.378812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>-0.257748</td>\n",
       "      <td>0.115739</td>\n",
       "      <td>0.206754</td>\n",
       "      <td>-0.436757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>0.210013</td>\n",
       "      <td>0.096093</td>\n",
       "      <td>-0.149230</td>\n",
       "      <td>0.193216</td>\n",
       "      <td>0.053952</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>-0.058770</td>\n",
       "      <td>-0.344187</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.577537</td>\n",
       "      <td>0.222682</td>\n",
       "      <td>0.210244</td>\n",
       "      <td>-0.430696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>-0.168814</td>\n",
       "      <td>-0.030711</td>\n",
       "      <td>0.119717</td>\n",
       "      <td>-0.121475</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>-0.059894</td>\n",
       "      <td>0.093045</td>\n",
       "      <td>0.386784</td>\n",
       "      <td>-0.257748</td>\n",
       "      <td>-0.577537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.080155</td>\n",
       "      <td>-0.104764</td>\n",
       "      <td>0.345877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0.276326</td>\n",
       "      <td>0.118261</td>\n",
       "      <td>-0.181053</td>\n",
       "      <td>0.101389</td>\n",
       "      <td>0.070511</td>\n",
       "      <td>0.137979</td>\n",
       "      <td>-0.072042</td>\n",
       "      <td>-0.213177</td>\n",
       "      <td>0.115739</td>\n",
       "      <td>0.222682</td>\n",
       "      <td>-0.080155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>-0.391724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>0.068001</td>\n",
       "      <td>0.210041</td>\n",
       "      <td>-0.161736</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>-0.032019</td>\n",
       "      <td>-0.011981</td>\n",
       "      <td>-0.096439</td>\n",
       "      <td>0.206754</td>\n",
       "      <td>0.210244</td>\n",
       "      <td>-0.104764</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.344029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.225439</td>\n",
       "      <td>-0.280937</td>\n",
       "      <td>0.433798</td>\n",
       "      <td>-0.144931</td>\n",
       "      <td>-0.085239</td>\n",
       "      <td>-0.028046</td>\n",
       "      <td>0.137230</td>\n",
       "      <td>0.421741</td>\n",
       "      <td>-0.436757</td>\n",
       "      <td>-0.430696</td>\n",
       "      <td>0.345877</td>\n",
       "      <td>-0.391724</td>\n",
       "      <td>-0.344029</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age       sex        cp  trestbps      chol       fbs  \\\n",
       "age       1.000000 -0.098447 -0.068653  0.279351  0.213678  0.121308   \n",
       "sex      -0.098447  1.000000 -0.049353 -0.056769 -0.197912  0.045032   \n",
       "cp       -0.068653 -0.049353  1.000000  0.047608 -0.076904  0.094444   \n",
       "trestbps  0.279351 -0.056769  0.047608  1.000000  0.123174  0.177531   \n",
       "chol      0.213678 -0.197912 -0.076904  0.123174  1.000000  0.013294   \n",
       "fbs       0.121308  0.045032  0.094444  0.177531  0.013294  1.000000   \n",
       "restecg  -0.116211 -0.058196  0.044421 -0.114103 -0.151040 -0.084189   \n",
       "thalach  -0.398522 -0.044020  0.295762 -0.046698 -0.009940 -0.008567   \n",
       "exang     0.096801  0.141664 -0.394280  0.067616  0.067023  0.025665   \n",
       "oldpeak   0.210013  0.096093 -0.149230  0.193216  0.053952  0.005747   \n",
       "slope    -0.168814 -0.030711  0.119717 -0.121475 -0.004038 -0.059894   \n",
       "ca        0.276326  0.118261 -0.181053  0.101389  0.070511  0.137979   \n",
       "thal      0.068001  0.210041 -0.161736  0.062210  0.098803 -0.032019   \n",
       "target   -0.225439 -0.280937  0.433798 -0.144931 -0.085239 -0.028046   \n",
       "\n",
       "           restecg   thalach     exang   oldpeak     slope        ca  \\\n",
       "age      -0.116211 -0.398522  0.096801  0.210013 -0.168814  0.276326   \n",
       "sex      -0.058196 -0.044020  0.141664  0.096093 -0.030711  0.118261   \n",
       "cp        0.044421  0.295762 -0.394280 -0.149230  0.119717 -0.181053   \n",
       "trestbps -0.114103 -0.046698  0.067616  0.193216 -0.121475  0.101389   \n",
       "chol     -0.151040 -0.009940  0.067023  0.053952 -0.004038  0.070511   \n",
       "fbs      -0.084189 -0.008567  0.025665  0.005747 -0.059894  0.137979   \n",
       "restecg   1.000000  0.044123 -0.070733 -0.058770  0.093045 -0.072042   \n",
       "thalach   0.044123  1.000000 -0.378812 -0.344187  0.386784 -0.213177   \n",
       "exang    -0.070733 -0.378812  1.000000  0.288223 -0.257748  0.115739   \n",
       "oldpeak  -0.058770 -0.344187  0.288223  1.000000 -0.577537  0.222682   \n",
       "slope     0.093045  0.386784 -0.257748 -0.577537  1.000000 -0.080155   \n",
       "ca       -0.072042 -0.213177  0.115739  0.222682 -0.080155  1.000000   \n",
       "thal     -0.011981 -0.096439  0.206754  0.210244 -0.104764  0.151832   \n",
       "target    0.137230  0.421741 -0.436757 -0.430696  0.345877 -0.391724   \n",
       "\n",
       "              thal    target  \n",
       "age       0.068001 -0.225439  \n",
       "sex       0.210041 -0.280937  \n",
       "cp       -0.161736  0.433798  \n",
       "trestbps  0.062210 -0.144931  \n",
       "chol      0.098803 -0.085239  \n",
       "fbs      -0.032019 -0.028046  \n",
       "restecg  -0.011981  0.137230  \n",
       "thalach  -0.096439  0.421741  \n",
       "exang     0.206754 -0.436757  \n",
       "oldpeak   0.210244 -0.430696  \n",
       "slope    -0.104764  0.345877  \n",
       "ca        0.151832 -0.391724  \n",
       "thal      1.000000 -0.344029  \n",
       "target   -0.344029  1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target      1.000000\n",
      "exang       0.436757\n",
      "cp          0.433798\n",
      "oldpeak     0.430696\n",
      "thalach     0.421741\n",
      "ca          0.391724\n",
      "slope       0.345877\n",
      "thal        0.344029\n",
      "sex         0.280937\n",
      "age         0.225439\n",
      "trestbps    0.144931\n",
      "restecg     0.137230\n",
      "chol        0.085239\n",
      "fbs         0.028046\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data.corr()[\"target\"].abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that most columns are moderately correlated with target, but 'fbs' and 'chol' are very weakly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18e23707448>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of patience without heart problems:  45.54455445544554\n",
      "Percentage of patience with severe heart problems:  54.45544554455446\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of patience without heart problems: \",(Y==0).sum()*100/len(data))\n",
    "print(\"Percentage of patience with severe heart problems: \",(Y==1).sum()*100/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Probability of People')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.kdeplot(data[data[\"target\"]==1][\"age\"], color=\"blue\", label=\"heart disease\")\n",
    "sns.kdeplot(data[data[\"target\"]==0][\"age\"], color=\"green\", label=\"no heart disease\")\n",
    "ax.set_xlabel(\"Age\")\n",
    "ax.set_ylabel(\"Probability of People\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((212, 13), (91, 13), (212,), (91,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,Y_train.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train,Y_train)\n",
    "Y_pred_LogReg = LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy achieved using Logistic Regression is: 81.31868131868131\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy achieved using Logistic Regression is: \",end=\"\")\n",
    "LogRegscore=LogReg.score(X_test,Y_test)*100\n",
    "print(LogRegscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.31868131868131"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_pred_LogReg,Y_test)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB = GaussianNB()\n",
    "NB.fit(X_train,Y_train)\n",
    "Y_pred_NB = NB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy achieved using Naive Bayes is: 80.21978021978022\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy achieved using Naive Bayes is: \",end=\"\")\n",
    "NBscore=NB.score(X_test,Y_test)*100\n",
    "print(NBscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of k: 1  cross val score:  73.13399778516057\n",
      "value of k: 3  cross val score:  77.82945736434108\n",
      "value of k: 5  cross val score:  80.21040974529345\n",
      "value of k: 7  cross val score:  82.547065337763\n",
      "value of k: 9  cross val score:  82.547065337763\n",
      "value of k: 11  cross val score:  84.42967884828349\n",
      "value of k: 13  cross val score:  83.02325581395348\n",
      "value of k: 15  cross val score:  83.48837209302324\n",
      "value of k: 17  cross val score:  82.08194905869324\n",
      "value of k: 19  cross val score:  82.547065337763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "for k in range(1, 20, 2):\n",
    "    KNN = KNeighborsClassifier(n_neighbors = k)\n",
    "    score = cross_val_score(KNN, X_train, Y_train)\n",
    "    print(\"value of k:\",k,\" cross val score: \", score.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy achieved using KNN is: 81.31868131868131\n"
     ]
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=11)\n",
    "KNN.fit(X_train,Y_train)\n",
    "Y_pred_KNN=KNN.predict(X_test)\n",
    "print(\"The accuracy achieved using KNN is: \",end=\"\")\n",
    "KNNscore=KNN.score(X_test,Y_test)*100\n",
    "print(KNN.score(X_test,Y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=0.1,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "DT=DecisionTreeClassifier(random_state=0)\n",
    "depth=[i+1 for i in range(10)]\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "min_samples_splits = np.linspace(0.1, 1.0,\n",
    "                                 10, endpoint=True)\n",
    "grid={'max_depth':depth, 'criterion':criterion, 'min_samples_split':min_samples_splits }\n",
    "abc= GridSearchCV(DT,grid)\n",
    "abc.fit(X_train,Y_train)\n",
    "\n",
    "abc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 0.1}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_params=abc.best_params_\n",
    "dt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy achieved using DecisionTreeClassifier is: 75.82417582417582\n"
     ]
    }
   ],
   "source": [
    "DT=DecisionTreeClassifier(max_depth=3,criterion='entropy',min_samples_split=.1,random_state=0)\n",
    "DT.fit(X_train,Y_train)\n",
    "print(\"The accuracy achieved using DecisionTreeClassifier is: \",end=\"\")\n",
    "DTscore=DT.score(X_test,Y_test)*100\n",
    "print(DTscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=2.0, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=0.2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "RF=RandomForestClassifier(random_state=1)\n",
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "\n",
    "grid={'max_depth':max_depths,'min_samples_split':min_samples_splits }\n",
    "abc= GridSearchCV(RF,grid)\n",
    "abc.fit(X_train,Y_train)\n",
    "abc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 0.1}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_params=abc.best_params_\n",
    "RF_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy achieved using RandomForestClassifier is: 82.41758241758241\n"
     ]
    }
   ],
   "source": [
    "RF=RandomForestClassifier(random_state=1,max_depth=3,min_samples_split=.1)\n",
    "RF.fit(X_train,Y_train)\n",
    "print(\"The accuracy achieved using RandomForestClassifier is: \",end=\"\")\n",
    "RFscore=RF.score(X_test,Y_test)*100\n",
    "\n",
    "print(RFscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "grid = {'C' : [1,10,25,50,75,1e2, 1e3],\n",
    "       'gamma' : [1,.1,0.01,1e-3, 1e-4]}\n",
    "\n",
    "\n",
    "SVM_clf = svm.SVC(kernel='linear')\n",
    "abc = GridSearchCV(SVM_clf, grid)\n",
    "abc.fit(X_train, Y_train)\n",
    "abc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_params=abc.best_params_\n",
    "SVM_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy achieved using SVM is: 80.21978021978022\n"
     ]
    }
   ],
   "source": [
    "SVM_clf = svm.SVC(kernel='linear',C=1,gamma=1)\n",
    "SVM_clf.fit(X_train,Y_train)\n",
    "print(\"The accuracy achieved using SVM is: \",end=\"\")\n",
    "SVMscore=SVM_clf.score(X_test,Y_test)*100\n",
    "print(SVMscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy achieved using XGBoost is: 80.21978021978022\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "XGB_clf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=0)\n",
    "XGB_clf.fit(X_train, Y_train)\n",
    "\n",
    "print(\"The accuracy achieved using XGBoost is: \",end=\"\")\n",
    "XGBscore=XGB_clf.score(X_test,Y_test)*100\n",
    "print(XGBscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16,activation='relu',input_dim=13))\n",
    "model.add(Dense(16,activation='tanh'))\n",
    "model.add(Dense(1,activation='sigmoid',kernel_regularizer=keras.regularizers.l1_l2(.001)))\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "212/212 [==============================] - 0s 1ms/step - loss: 0.2733 - accuracy: 0.5189\n",
      "Epoch 2/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.2704 - accuracy: 0.5283\n",
      "Epoch 3/1000\n",
      "212/212 [==============================] - 0s 104us/step - loss: 0.2677 - accuracy: 0.5330\n",
      "Epoch 4/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.2649 - accuracy: 0.5330\n",
      "Epoch 5/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.2624 - accuracy: 0.5519\n",
      "Epoch 6/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.2599 - accuracy: 0.5660\n",
      "Epoch 7/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.2573 - accuracy: 0.5802\n",
      "Epoch 8/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.2549 - accuracy: 0.5849\n",
      "Epoch 9/1000\n",
      "212/212 [==============================] - 0s 95us/step - loss: 0.2527 - accuracy: 0.6038\n",
      "Epoch 10/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.2504 - accuracy: 0.6179\n",
      "Epoch 11/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.2482 - accuracy: 0.6321\n",
      "Epoch 12/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.2461 - accuracy: 0.6321\n",
      "Epoch 13/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.2440 - accuracy: 0.6462\n",
      "Epoch 14/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.2420 - accuracy: 0.6509\n",
      "Epoch 15/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.2400 - accuracy: 0.6557\n",
      "Epoch 16/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.2382 - accuracy: 0.6651\n",
      "Epoch 17/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.2363 - accuracy: 0.6557\n",
      "Epoch 18/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.2346 - accuracy: 0.6604\n",
      "Epoch 19/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.2329 - accuracy: 0.6557\n",
      "Epoch 20/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.2312 - accuracy: 0.6651\n",
      "Epoch 21/1000\n",
      "212/212 [==============================] - 0s 99us/step - loss: 0.2295 - accuracy: 0.6651\n",
      "Epoch 22/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.2279 - accuracy: 0.6698\n",
      "Epoch 23/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.2263 - accuracy: 0.6698\n",
      "Epoch 24/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.2248 - accuracy: 0.6745\n",
      "Epoch 25/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.2233 - accuracy: 0.6840\n",
      "Epoch 26/1000\n",
      "212/212 [==============================] - 0s 95us/step - loss: 0.2218 - accuracy: 0.6840\n",
      "Epoch 27/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.2203 - accuracy: 0.6887\n",
      "Epoch 28/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.2189 - accuracy: 0.6981\n",
      "Epoch 29/1000\n",
      "212/212 [==============================] - 0s 97us/step - loss: 0.2176 - accuracy: 0.6934\n",
      "Epoch 30/1000\n",
      "212/212 [==============================] - 0s 88us/step - loss: 0.2162 - accuracy: 0.6981\n",
      "Epoch 31/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.2149 - accuracy: 0.7075\n",
      "Epoch 32/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.2136 - accuracy: 0.7075\n",
      "Epoch 33/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.2124 - accuracy: 0.7217\n",
      "Epoch 34/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.2112 - accuracy: 0.7264\n",
      "Epoch 35/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.2100 - accuracy: 0.7264\n",
      "Epoch 36/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.2089 - accuracy: 0.7264\n",
      "Epoch 37/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.2077 - accuracy: 0.7264\n",
      "Epoch 38/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.2066 - accuracy: 0.7264\n",
      "Epoch 39/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.2055 - accuracy: 0.7311\n",
      "Epoch 40/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.2044 - accuracy: 0.7358\n",
      "Epoch 41/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.2034 - accuracy: 0.7358\n",
      "Epoch 42/1000\n",
      "212/212 [==============================] - 0s 97us/step - loss: 0.2023 - accuracy: 0.7358\n",
      "Epoch 43/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.2013 - accuracy: 0.7311\n",
      "Epoch 44/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.2003 - accuracy: 0.7358\n",
      "Epoch 45/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1994 - accuracy: 0.7358\n",
      "Epoch 46/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1984 - accuracy: 0.7358\n",
      "Epoch 47/1000\n",
      "212/212 [==============================] - 0s 99us/step - loss: 0.1975 - accuracy: 0.7358\n",
      "Epoch 48/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1965 - accuracy: 0.7358\n",
      "Epoch 49/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1956 - accuracy: 0.7311\n",
      "Epoch 50/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1948 - accuracy: 0.7311\n",
      "Epoch 51/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1939 - accuracy: 0.7358\n",
      "Epoch 52/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1930 - accuracy: 0.7358\n",
      "Epoch 53/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.1921 - accuracy: 0.7406\n",
      "Epoch 54/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1913 - accuracy: 0.7358\n",
      "Epoch 55/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1905 - accuracy: 0.7453\n",
      "Epoch 56/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1897 - accuracy: 0.7500\n",
      "Epoch 57/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1890 - accuracy: 0.7500\n",
      "Epoch 58/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1882 - accuracy: 0.7500\n",
      "Epoch 59/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1874 - accuracy: 0.7500\n",
      "Epoch 60/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1867 - accuracy: 0.7500\n",
      "Epoch 61/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1859 - accuracy: 0.7500\n",
      "Epoch 62/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1852 - accuracy: 0.7500\n",
      "Epoch 63/1000\n",
      "212/212 [==============================] - 0s 88us/step - loss: 0.1846 - accuracy: 0.7547\n",
      "Epoch 64/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1838 - accuracy: 0.7594\n",
      "Epoch 65/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1832 - accuracy: 0.7594\n",
      "Epoch 66/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1825 - accuracy: 0.7642\n",
      "Epoch 67/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1819 - accuracy: 0.7642\n",
      "Epoch 68/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1812 - accuracy: 0.7642\n",
      "Epoch 69/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1806 - accuracy: 0.7642\n",
      "Epoch 70/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1799 - accuracy: 0.7642\n",
      "Epoch 71/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1793 - accuracy: 0.7642\n",
      "Epoch 72/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1787 - accuracy: 0.7642\n",
      "Epoch 73/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1781 - accuracy: 0.7642\n",
      "Epoch 74/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1775 - accuracy: 0.7642\n",
      "Epoch 75/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1769 - accuracy: 0.7642\n",
      "Epoch 76/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1763 - accuracy: 0.7689\n",
      "Epoch 77/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1758 - accuracy: 0.7689\n",
      "Epoch 78/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1752 - accuracy: 0.7689\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 76us/step - loss: 0.1747 - accuracy: 0.7736\n",
      "Epoch 80/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1742 - accuracy: 0.7736\n",
      "Epoch 81/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1736 - accuracy: 0.7736\n",
      "Epoch 82/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1731 - accuracy: 0.7736\n",
      "Epoch 83/1000\n",
      "212/212 [==============================] - 0s 192us/step - loss: 0.1726 - accuracy: 0.7736\n",
      "Epoch 84/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1720 - accuracy: 0.7736\n",
      "Epoch 85/1000\n",
      "212/212 [==============================] - 0s 99us/step - loss: 0.1715 - accuracy: 0.7736\n",
      "Epoch 86/1000\n",
      "212/212 [==============================] - 0s 59us/step - loss: 0.1711 - accuracy: 0.7736\n",
      "Epoch 87/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1706 - accuracy: 0.7736\n",
      "Epoch 88/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1701 - accuracy: 0.7783\n",
      "Epoch 89/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1696 - accuracy: 0.7783\n",
      "Epoch 90/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1691 - accuracy: 0.7783\n",
      "Epoch 91/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1686 - accuracy: 0.7783\n",
      "Epoch 92/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1681 - accuracy: 0.7830\n",
      "Epoch 93/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1677 - accuracy: 0.7830\n",
      "Epoch 94/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1672 - accuracy: 0.7830\n",
      "Epoch 95/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1667 - accuracy: 0.7830\n",
      "Epoch 96/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1663 - accuracy: 0.7830\n",
      "Epoch 97/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1658 - accuracy: 0.7830\n",
      "Epoch 98/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1654 - accuracy: 0.7830\n",
      "Epoch 99/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1650 - accuracy: 0.7877\n",
      "Epoch 100/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1645 - accuracy: 0.7877\n",
      "Epoch 101/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1641 - accuracy: 0.7877\n",
      "Epoch 102/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1637 - accuracy: 0.7925\n",
      "Epoch 103/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1633 - accuracy: 0.7925\n",
      "Epoch 104/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1629 - accuracy: 0.7925\n",
      "Epoch 105/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1625 - accuracy: 0.7925\n",
      "Epoch 106/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1621 - accuracy: 0.7925\n",
      "Epoch 107/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1616 - accuracy: 0.7925\n",
      "Epoch 108/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1613 - accuracy: 0.7925\n",
      "Epoch 109/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1609 - accuracy: 0.7972\n",
      "Epoch 110/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1605 - accuracy: 0.7972\n",
      "Epoch 111/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1602 - accuracy: 0.8019\n",
      "Epoch 112/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1598 - accuracy: 0.8019\n",
      "Epoch 113/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1594 - accuracy: 0.8019\n",
      "Epoch 114/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1590 - accuracy: 0.8019\n",
      "Epoch 115/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1587 - accuracy: 0.8066\n",
      "Epoch 116/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1584 - accuracy: 0.8066\n",
      "Epoch 117/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1580 - accuracy: 0.8066\n",
      "Epoch 118/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1577 - accuracy: 0.8066\n",
      "Epoch 119/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1573 - accuracy: 0.8066\n",
      "Epoch 120/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1570 - accuracy: 0.8066\n",
      "Epoch 121/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1566 - accuracy: 0.8066\n",
      "Epoch 122/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1563 - accuracy: 0.8066\n",
      "Epoch 123/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1560 - accuracy: 0.8066\n",
      "Epoch 124/1000\n",
      "212/212 [==============================] - 0s 111us/step - loss: 0.1556 - accuracy: 0.8113\n",
      "Epoch 125/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1553 - accuracy: 0.8113\n",
      "Epoch 126/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1550 - accuracy: 0.8113\n",
      "Epoch 127/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1547 - accuracy: 0.8113\n",
      "Epoch 128/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1544 - accuracy: 0.8113\n",
      "Epoch 129/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1541 - accuracy: 0.8113\n",
      "Epoch 130/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1538 - accuracy: 0.8113\n",
      "Epoch 131/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1535 - accuracy: 0.8113\n",
      "Epoch 132/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1532 - accuracy: 0.8160\n",
      "Epoch 133/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1529 - accuracy: 0.8160\n",
      "Epoch 134/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1526 - accuracy: 0.8208\n",
      "Epoch 135/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1523 - accuracy: 0.8255\n",
      "Epoch 136/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1521 - accuracy: 0.8208\n",
      "Epoch 137/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1518 - accuracy: 0.8255\n",
      "Epoch 138/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1515 - accuracy: 0.8255\n",
      "Epoch 139/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1513 - accuracy: 0.8255\n",
      "Epoch 140/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1510 - accuracy: 0.8255\n",
      "Epoch 141/1000\n",
      "212/212 [==============================] - 0s 50us/step - loss: 0.1507 - accuracy: 0.8255\n",
      "Epoch 142/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1504 - accuracy: 0.8255\n",
      "Epoch 143/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1502 - accuracy: 0.8255\n",
      "Epoch 144/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1500 - accuracy: 0.8255\n",
      "Epoch 145/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1497 - accuracy: 0.8255\n",
      "Epoch 146/1000\n",
      "212/212 [==============================] - 0s 92us/step - loss: 0.1494 - accuracy: 0.8255\n",
      "Epoch 147/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1492 - accuracy: 0.8208\n",
      "Epoch 148/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1489 - accuracy: 0.8208\n",
      "Epoch 149/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1487 - accuracy: 0.8208\n",
      "Epoch 150/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1485 - accuracy: 0.8208\n",
      "Epoch 151/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1482 - accuracy: 0.8208\n",
      "Epoch 152/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1480 - accuracy: 0.8255\n",
      "Epoch 153/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1478 - accuracy: 0.8302\n",
      "Epoch 154/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1475 - accuracy: 0.8302\n",
      "Epoch 155/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1473 - accuracy: 0.8302\n",
      "Epoch 156/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1471 - accuracy: 0.8302\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 73us/step - loss: 0.1468 - accuracy: 0.8302\n",
      "Epoch 158/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1466 - accuracy: 0.8302\n",
      "Epoch 159/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1464 - accuracy: 0.8302\n",
      "Epoch 160/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1462 - accuracy: 0.8302\n",
      "Epoch 161/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1460 - accuracy: 0.8302\n",
      "Epoch 162/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1457 - accuracy: 0.8302\n",
      "Epoch 163/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1455 - accuracy: 0.8302\n",
      "Epoch 164/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1453 - accuracy: 0.8302\n",
      "Epoch 165/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1451 - accuracy: 0.8302\n",
      "Epoch 166/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1449 - accuracy: 0.8302\n",
      "Epoch 167/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1447 - accuracy: 0.8302\n",
      "Epoch 168/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1445 - accuracy: 0.8302\n",
      "Epoch 169/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1443 - accuracy: 0.8302\n",
      "Epoch 170/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.1441 - accuracy: 0.8302\n",
      "Epoch 171/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1439 - accuracy: 0.8302\n",
      "Epoch 172/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1437 - accuracy: 0.8302\n",
      "Epoch 173/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1435 - accuracy: 0.8302\n",
      "Epoch 174/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1433 - accuracy: 0.8302\n",
      "Epoch 175/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1431 - accuracy: 0.8302\n",
      "Epoch 176/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1429 - accuracy: 0.8302\n",
      "Epoch 177/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1427 - accuracy: 0.8302\n",
      "Epoch 178/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1426 - accuracy: 0.8302\n",
      "Epoch 179/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1424 - accuracy: 0.8302\n",
      "Epoch 180/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1422 - accuracy: 0.8302\n",
      "Epoch 181/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1420 - accuracy: 0.8302\n",
      "Epoch 182/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1418 - accuracy: 0.8302\n",
      "Epoch 183/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1416 - accuracy: 0.8302\n",
      "Epoch 184/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1415 - accuracy: 0.8302\n",
      "Epoch 185/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1413 - accuracy: 0.8302\n",
      "Epoch 186/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1411 - accuracy: 0.8302\n",
      "Epoch 187/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1409 - accuracy: 0.8302\n",
      "Epoch 188/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1407 - accuracy: 0.8302\n",
      "Epoch 189/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1406 - accuracy: 0.8302\n",
      "Epoch 190/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1404 - accuracy: 0.8302\n",
      "Epoch 191/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1402 - accuracy: 0.8349\n",
      "Epoch 192/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1400 - accuracy: 0.8349\n",
      "Epoch 193/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1399 - accuracy: 0.8396\n",
      "Epoch 194/1000\n",
      "212/212 [==============================] - 0s 102us/step - loss: 0.1397 - accuracy: 0.8396\n",
      "Epoch 195/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1395 - accuracy: 0.8443\n",
      "Epoch 196/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1394 - accuracy: 0.8396\n",
      "Epoch 197/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1392 - accuracy: 0.8443\n",
      "Epoch 198/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1390 - accuracy: 0.8443\n",
      "Epoch 199/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1389 - accuracy: 0.8443\n",
      "Epoch 200/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1387 - accuracy: 0.8443\n",
      "Epoch 201/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1385 - accuracy: 0.8443\n",
      "Epoch 202/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1384 - accuracy: 0.8491\n",
      "Epoch 203/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1382 - accuracy: 0.8491\n",
      "Epoch 204/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1380 - accuracy: 0.8491\n",
      "Epoch 205/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1379 - accuracy: 0.8491\n",
      "Epoch 206/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1377 - accuracy: 0.8491\n",
      "Epoch 207/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1376 - accuracy: 0.8491\n",
      "Epoch 208/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1374 - accuracy: 0.8491\n",
      "Epoch 209/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1372 - accuracy: 0.8491\n",
      "Epoch 210/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1371 - accuracy: 0.8491\n",
      "Epoch 211/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1369 - accuracy: 0.8491\n",
      "Epoch 212/1000\n",
      "212/212 [==============================] - 0s 59us/step - loss: 0.1368 - accuracy: 0.8491\n",
      "Epoch 213/1000\n",
      "212/212 [==============================] - 0s 95us/step - loss: 0.1366 - accuracy: 0.8491\n",
      "Epoch 214/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1365 - accuracy: 0.8585\n",
      "Epoch 215/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1363 - accuracy: 0.8585\n",
      "Epoch 216/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1362 - accuracy: 0.8585\n",
      "Epoch 217/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1361 - accuracy: 0.8585\n",
      "Epoch 218/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1359 - accuracy: 0.8585\n",
      "Epoch 219/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1358 - accuracy: 0.8585\n",
      "Epoch 220/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1356 - accuracy: 0.8585\n",
      "Epoch 221/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1355 - accuracy: 0.8585\n",
      "Epoch 222/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1354 - accuracy: 0.8585\n",
      "Epoch 223/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1352 - accuracy: 0.8585\n",
      "Epoch 224/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1351 - accuracy: 0.8585\n",
      "Epoch 225/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1349 - accuracy: 0.8585\n",
      "Epoch 226/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1348 - accuracy: 0.8585\n",
      "Epoch 227/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1347 - accuracy: 0.8585\n",
      "Epoch 228/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1345 - accuracy: 0.8585\n",
      "Epoch 229/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1344 - accuracy: 0.8585\n",
      "Epoch 230/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1343 - accuracy: 0.8585\n",
      "Epoch 231/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1341 - accuracy: 0.8585\n",
      "Epoch 232/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1340 - accuracy: 0.8585\n",
      "Epoch 233/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1339 - accuracy: 0.8585\n",
      "Epoch 234/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1337 - accuracy: 0.8585\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 78us/step - loss: 0.1336 - accuracy: 0.8585\n",
      "Epoch 236/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1335 - accuracy: 0.8585\n",
      "Epoch 237/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1334 - accuracy: 0.8585\n",
      "Epoch 238/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1332 - accuracy: 0.8585\n",
      "Epoch 239/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1331 - accuracy: 0.8585\n",
      "Epoch 240/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1330 - accuracy: 0.8585\n",
      "Epoch 241/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1329 - accuracy: 0.8585\n",
      "Epoch 242/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1328 - accuracy: 0.8585\n",
      "Epoch 243/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1326 - accuracy: 0.8585\n",
      "Epoch 244/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1325 - accuracy: 0.8585\n",
      "Epoch 245/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1324 - accuracy: 0.8585\n",
      "Epoch 246/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1323 - accuracy: 0.8585\n",
      "Epoch 247/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1322 - accuracy: 0.8585\n",
      "Epoch 248/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1320 - accuracy: 0.8585\n",
      "Epoch 249/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1319 - accuracy: 0.8585\n",
      "Epoch 250/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1318 - accuracy: 0.8585\n",
      "Epoch 251/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1317 - accuracy: 0.8585\n",
      "Epoch 252/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1316 - accuracy: 0.8585\n",
      "Epoch 253/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1314 - accuracy: 0.8585\n",
      "Epoch 254/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1313 - accuracy: 0.8585\n",
      "Epoch 255/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1312 - accuracy: 0.8585\n",
      "Epoch 256/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1311 - accuracy: 0.8585\n",
      "Epoch 257/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1310 - accuracy: 0.8585\n",
      "Epoch 258/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1309 - accuracy: 0.8585\n",
      "Epoch 259/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1307 - accuracy: 0.8585\n",
      "Epoch 260/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1306 - accuracy: 0.8632\n",
      "Epoch 261/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1305 - accuracy: 0.8632\n",
      "Epoch 262/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1304 - accuracy: 0.8632\n",
      "Epoch 263/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1303 - accuracy: 0.8632\n",
      "Epoch 264/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1302 - accuracy: 0.8632\n",
      "Epoch 265/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1301 - accuracy: 0.8632\n",
      "Epoch 266/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1300 - accuracy: 0.8632\n",
      "Epoch 267/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1299 - accuracy: 0.8632\n",
      "Epoch 268/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1298 - accuracy: 0.8632\n",
      "Epoch 269/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1296 - accuracy: 0.8632\n",
      "Epoch 270/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1295 - accuracy: 0.8632\n",
      "Epoch 271/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1294 - accuracy: 0.8632\n",
      "Epoch 272/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1293 - accuracy: 0.8632\n",
      "Epoch 273/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1292 - accuracy: 0.8632\n",
      "Epoch 274/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1291 - accuracy: 0.8632\n",
      "Epoch 275/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1290 - accuracy: 0.8632\n",
      "Epoch 276/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1289 - accuracy: 0.8632\n",
      "Epoch 277/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1288 - accuracy: 0.8632\n",
      "Epoch 278/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1287 - accuracy: 0.8632\n",
      "Epoch 279/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1286 - accuracy: 0.8632\n",
      "Epoch 280/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1285 - accuracy: 0.8679\n",
      "Epoch 281/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1284 - accuracy: 0.8679\n",
      "Epoch 282/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1283 - accuracy: 0.8679\n",
      "Epoch 283/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1282 - accuracy: 0.8679\n",
      "Epoch 284/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1281 - accuracy: 0.8679\n",
      "Epoch 285/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1280 - accuracy: 0.8679\n",
      "Epoch 286/1000\n",
      "212/212 [==============================] - 0s 92us/step - loss: 0.1279 - accuracy: 0.8679\n",
      "Epoch 287/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1278 - accuracy: 0.8679\n",
      "Epoch 288/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1277 - accuracy: 0.8679\n",
      "Epoch 289/1000\n",
      "212/212 [==============================] - 0s 90us/step - loss: 0.1276 - accuracy: 0.8679\n",
      "Epoch 290/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1275 - accuracy: 0.8679\n",
      "Epoch 291/1000\n",
      "212/212 [==============================] - 0s 90us/step - loss: 0.1274 - accuracy: 0.8679\n",
      "Epoch 292/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1273 - accuracy: 0.8679\n",
      "Epoch 293/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1272 - accuracy: 0.8679\n",
      "Epoch 294/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1271 - accuracy: 0.8679\n",
      "Epoch 295/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1270 - accuracy: 0.8679\n",
      "Epoch 296/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1269 - accuracy: 0.8679\n",
      "Epoch 297/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1268 - accuracy: 0.8679\n",
      "Epoch 298/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1267 - accuracy: 0.8679\n",
      "Epoch 299/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1266 - accuracy: 0.8679\n",
      "Epoch 300/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1265 - accuracy: 0.8679\n",
      "Epoch 301/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1264 - accuracy: 0.8679\n",
      "Epoch 302/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1263 - accuracy: 0.8679\n",
      "Epoch 303/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1263 - accuracy: 0.8679\n",
      "Epoch 304/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1262 - accuracy: 0.8679\n",
      "Epoch 305/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1261 - accuracy: 0.8679\n",
      "Epoch 306/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1260 - accuracy: 0.8679\n",
      "Epoch 307/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1259 - accuracy: 0.8679\n",
      "Epoch 308/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1258 - accuracy: 0.8679\n",
      "Epoch 309/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1257 - accuracy: 0.8679\n",
      "Epoch 310/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1256 - accuracy: 0.8679\n",
      "Epoch 311/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1255 - accuracy: 0.8679\n",
      "Epoch 312/1000\n",
      "212/212 [==============================] - 0s 88us/step - loss: 0.1255 - accuracy: 0.8679\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 83us/step - loss: 0.1254 - accuracy: 0.8679\n",
      "Epoch 314/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1253 - accuracy: 0.8679\n",
      "Epoch 315/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1252 - accuracy: 0.8679\n",
      "Epoch 316/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1251 - accuracy: 0.8679\n",
      "Epoch 317/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1250 - accuracy: 0.8679\n",
      "Epoch 318/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1249 - accuracy: 0.8679\n",
      "Epoch 319/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1249 - accuracy: 0.8679\n",
      "Epoch 320/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1248 - accuracy: 0.8679\n",
      "Epoch 321/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1247 - accuracy: 0.8679\n",
      "Epoch 322/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1246 - accuracy: 0.8679\n",
      "Epoch 323/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1245 - accuracy: 0.8679\n",
      "Epoch 324/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1244 - accuracy: 0.8679\n",
      "Epoch 325/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1244 - accuracy: 0.8679\n",
      "Epoch 326/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1243 - accuracy: 0.8679\n",
      "Epoch 327/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1242 - accuracy: 0.8679\n",
      "Epoch 328/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1241 - accuracy: 0.8679\n",
      "Epoch 329/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1240 - accuracy: 0.8679\n",
      "Epoch 330/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1240 - accuracy: 0.8679\n",
      "Epoch 331/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1239 - accuracy: 0.8679\n",
      "Epoch 332/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1238 - accuracy: 0.8679\n",
      "Epoch 333/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1237 - accuracy: 0.8679\n",
      "Epoch 334/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1236 - accuracy: 0.8679\n",
      "Epoch 335/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1235 - accuracy: 0.8679\n",
      "Epoch 336/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1235 - accuracy: 0.8679\n",
      "Epoch 337/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1234 - accuracy: 0.8679\n",
      "Epoch 338/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1233 - accuracy: 0.8679\n",
      "Epoch 339/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1233 - accuracy: 0.8679\n",
      "Epoch 340/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1232 - accuracy: 0.8679\n",
      "Epoch 341/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1231 - accuracy: 0.8679\n",
      "Epoch 342/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1230 - accuracy: 0.8679\n",
      "Epoch 343/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1229 - accuracy: 0.8679\n",
      "Epoch 344/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1228 - accuracy: 0.8679\n",
      "Epoch 345/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1228 - accuracy: 0.8679\n",
      "Epoch 346/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1227 - accuracy: 0.8679\n",
      "Epoch 347/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1226 - accuracy: 0.8679\n",
      "Epoch 348/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1225 - accuracy: 0.8679\n",
      "Epoch 349/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1225 - accuracy: 0.8679\n",
      "Epoch 350/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1224 - accuracy: 0.8679\n",
      "Epoch 351/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1223 - accuracy: 0.8679\n",
      "Epoch 352/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1222 - accuracy: 0.8726\n",
      "Epoch 353/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1222 - accuracy: 0.8726\n",
      "Epoch 354/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1221 - accuracy: 0.8726\n",
      "Epoch 355/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1220 - accuracy: 0.8726\n",
      "Epoch 356/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1219 - accuracy: 0.8726\n",
      "Epoch 357/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1219 - accuracy: 0.8726\n",
      "Epoch 358/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1218 - accuracy: 0.8726\n",
      "Epoch 359/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1217 - accuracy: 0.8726\n",
      "Epoch 360/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1216 - accuracy: 0.8726\n",
      "Epoch 361/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1216 - accuracy: 0.8726\n",
      "Epoch 362/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1215 - accuracy: 0.8726\n",
      "Epoch 363/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1214 - accuracy: 0.8726\n",
      "Epoch 364/1000\n",
      "212/212 [==============================] - 0s 59us/step - loss: 0.1214 - accuracy: 0.8726\n",
      "Epoch 365/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1213 - accuracy: 0.8726\n",
      "Epoch 366/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1212 - accuracy: 0.8726\n",
      "Epoch 367/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1211 - accuracy: 0.8726\n",
      "Epoch 368/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1211 - accuracy: 0.8726\n",
      "Epoch 369/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1210 - accuracy: 0.8726\n",
      "Epoch 370/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1209 - accuracy: 0.8726\n",
      "Epoch 371/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1209 - accuracy: 0.8726\n",
      "Epoch 372/1000\n",
      "212/212 [==============================] - 0s 59us/step - loss: 0.1208 - accuracy: 0.8726\n",
      "Epoch 373/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1207 - accuracy: 0.8726\n",
      "Epoch 374/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1207 - accuracy: 0.8726\n",
      "Epoch 375/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1206 - accuracy: 0.8726\n",
      "Epoch 376/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1205 - accuracy: 0.8726\n",
      "Epoch 377/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1205 - accuracy: 0.8726\n",
      "Epoch 378/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1204 - accuracy: 0.8726\n",
      "Epoch 379/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1203 - accuracy: 0.8726\n",
      "Epoch 380/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1202 - accuracy: 0.8726\n",
      "Epoch 381/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1202 - accuracy: 0.8726\n",
      "Epoch 382/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1201 - accuracy: 0.8726\n",
      "Epoch 383/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1201 - accuracy: 0.8726\n",
      "Epoch 384/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1200 - accuracy: 0.8726\n",
      "Epoch 385/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1199 - accuracy: 0.8726\n",
      "Epoch 386/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1199 - accuracy: 0.8726\n",
      "Epoch 387/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1198 - accuracy: 0.8774\n",
      "Epoch 388/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1197 - accuracy: 0.8774\n",
      "Epoch 389/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1197 - accuracy: 0.8774\n",
      "Epoch 390/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1196 - accuracy: 0.8774\n",
      "Epoch 391/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 85us/step - loss: 0.1195 - accuracy: 0.8774\n",
      "Epoch 392/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1195 - accuracy: 0.8774\n",
      "Epoch 393/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1194 - accuracy: 0.8774\n",
      "Epoch 394/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1193 - accuracy: 0.8774\n",
      "Epoch 395/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1193 - accuracy: 0.8774\n",
      "Epoch 396/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1192 - accuracy: 0.8774\n",
      "Epoch 397/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1191 - accuracy: 0.8774\n",
      "Epoch 398/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1191 - accuracy: 0.8774\n",
      "Epoch 399/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1190 - accuracy: 0.8774\n",
      "Epoch 400/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1190 - accuracy: 0.8774\n",
      "Epoch 401/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1189 - accuracy: 0.8774\n",
      "Epoch 402/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1188 - accuracy: 0.8774\n",
      "Epoch 403/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1188 - accuracy: 0.8774\n",
      "Epoch 404/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1187 - accuracy: 0.8774\n",
      "Epoch 405/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1187 - accuracy: 0.8774\n",
      "Epoch 406/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1186 - accuracy: 0.8774\n",
      "Epoch 407/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1185 - accuracy: 0.8774\n",
      "Epoch 408/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1185 - accuracy: 0.8821\n",
      "Epoch 409/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1184 - accuracy: 0.8821\n",
      "Epoch 410/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1184 - accuracy: 0.8821\n",
      "Epoch 411/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1183 - accuracy: 0.8821\n",
      "Epoch 412/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1182 - accuracy: 0.8821\n",
      "Epoch 413/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1182 - accuracy: 0.8821\n",
      "Epoch 414/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1181 - accuracy: 0.8821\n",
      "Epoch 415/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1180 - accuracy: 0.8821\n",
      "Epoch 416/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1180 - accuracy: 0.8821\n",
      "Epoch 417/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1179 - accuracy: 0.8821\n",
      "Epoch 418/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1179 - accuracy: 0.8821\n",
      "Epoch 419/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1178 - accuracy: 0.8821\n",
      "Epoch 420/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1178 - accuracy: 0.8821\n",
      "Epoch 421/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1177 - accuracy: 0.8821\n",
      "Epoch 422/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1176 - accuracy: 0.8821\n",
      "Epoch 423/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1176 - accuracy: 0.8821\n",
      "Epoch 424/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1175 - accuracy: 0.8821\n",
      "Epoch 425/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1175 - accuracy: 0.8821\n",
      "Epoch 426/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1174 - accuracy: 0.8821\n",
      "Epoch 427/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1173 - accuracy: 0.8821\n",
      "Epoch 428/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1173 - accuracy: 0.8821\n",
      "Epoch 429/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1172 - accuracy: 0.8821\n",
      "Epoch 430/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1172 - accuracy: 0.8821\n",
      "Epoch 431/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1171 - accuracy: 0.8821\n",
      "Epoch 432/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1171 - accuracy: 0.8821\n",
      "Epoch 433/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1170 - accuracy: 0.8821\n",
      "Epoch 434/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1170 - accuracy: 0.8821\n",
      "Epoch 435/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1169 - accuracy: 0.8821\n",
      "Epoch 436/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1168 - accuracy: 0.8821\n",
      "Epoch 437/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1168 - accuracy: 0.8821\n",
      "Epoch 438/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1167 - accuracy: 0.8821\n",
      "Epoch 439/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1167 - accuracy: 0.8821\n",
      "Epoch 440/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1166 - accuracy: 0.8821\n",
      "Epoch 441/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1166 - accuracy: 0.8821\n",
      "Epoch 442/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1165 - accuracy: 0.8821\n",
      "Epoch 443/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1164 - accuracy: 0.8821\n",
      "Epoch 444/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1164 - accuracy: 0.8821\n",
      "Epoch 445/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1163 - accuracy: 0.8821\n",
      "Epoch 446/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1163 - accuracy: 0.8821\n",
      "Epoch 447/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1162 - accuracy: 0.8821\n",
      "Epoch 448/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1162 - accuracy: 0.8821\n",
      "Epoch 449/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1161 - accuracy: 0.8821\n",
      "Epoch 450/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1161 - accuracy: 0.8821\n",
      "Epoch 451/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1160 - accuracy: 0.8821\n",
      "Epoch 452/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1160 - accuracy: 0.8821\n",
      "Epoch 453/1000\n",
      "212/212 [==============================] - 0s 98us/step - loss: 0.1159 - accuracy: 0.8821\n",
      "Epoch 454/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.1158 - accuracy: 0.8821\n",
      "Epoch 455/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1158 - accuracy: 0.8821\n",
      "Epoch 456/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1157 - accuracy: 0.8821\n",
      "Epoch 457/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1157 - accuracy: 0.8821\n",
      "Epoch 458/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1156 - accuracy: 0.8821\n",
      "Epoch 459/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1156 - accuracy: 0.8821\n",
      "Epoch 460/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1155 - accuracy: 0.8821\n",
      "Epoch 461/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1155 - accuracy: 0.8821\n",
      "Epoch 462/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1154 - accuracy: 0.8821\n",
      "Epoch 463/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1154 - accuracy: 0.8821\n",
      "Epoch 464/1000\n",
      "212/212 [==============================] - 0s 92us/step - loss: 0.1153 - accuracy: 0.8821\n",
      "Epoch 465/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1153 - accuracy: 0.8821\n",
      "Epoch 466/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1152 - accuracy: 0.8821\n",
      "Epoch 467/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1152 - accuracy: 0.8821\n",
      "Epoch 468/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1151 - accuracy: 0.8821\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 80us/step - loss: 0.1151 - accuracy: 0.8821\n",
      "Epoch 470/1000\n",
      "212/212 [==============================] - 0s 88us/step - loss: 0.1150 - accuracy: 0.8821\n",
      "Epoch 471/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.1150 - accuracy: 0.8821\n",
      "Epoch 472/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1149 - accuracy: 0.8868\n",
      "Epoch 473/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1148 - accuracy: 0.8821\n",
      "Epoch 474/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1148 - accuracy: 0.8821\n",
      "Epoch 475/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1147 - accuracy: 0.8868\n",
      "Epoch 476/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1147 - accuracy: 0.8868\n",
      "Epoch 477/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1146 - accuracy: 0.8868\n",
      "Epoch 478/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1146 - accuracy: 0.8868\n",
      "Epoch 479/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1145 - accuracy: 0.8868\n",
      "Epoch 480/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1145 - accuracy: 0.8868\n",
      "Epoch 481/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1144 - accuracy: 0.8868\n",
      "Epoch 482/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1144 - accuracy: 0.8868\n",
      "Epoch 483/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1143 - accuracy: 0.8868\n",
      "Epoch 484/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1143 - accuracy: 0.8868\n",
      "Epoch 485/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1142 - accuracy: 0.8868\n",
      "Epoch 486/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1142 - accuracy: 0.8868\n",
      "Epoch 487/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1141 - accuracy: 0.8868\n",
      "Epoch 488/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1141 - accuracy: 0.8868\n",
      "Epoch 489/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1140 - accuracy: 0.8868\n",
      "Epoch 490/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1139 - accuracy: 0.8868\n",
      "Epoch 491/1000\n",
      "212/212 [==============================] - 0s 97us/step - loss: 0.1139 - accuracy: 0.8868\n",
      "Epoch 492/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1138 - accuracy: 0.8868\n",
      "Epoch 493/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1138 - accuracy: 0.8868\n",
      "Epoch 494/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1137 - accuracy: 0.8868\n",
      "Epoch 495/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1137 - accuracy: 0.8868\n",
      "Epoch 496/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1136 - accuracy: 0.8868\n",
      "Epoch 497/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1136 - accuracy: 0.8868\n",
      "Epoch 498/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1135 - accuracy: 0.8868\n",
      "Epoch 499/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1135 - accuracy: 0.8868\n",
      "Epoch 500/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1134 - accuracy: 0.8868\n",
      "Epoch 501/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1134 - accuracy: 0.8868\n",
      "Epoch 502/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1133 - accuracy: 0.8868\n",
      "Epoch 503/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1133 - accuracy: 0.8868\n",
      "Epoch 504/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1132 - accuracy: 0.8868\n",
      "Epoch 505/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1132 - accuracy: 0.8868\n",
      "Epoch 506/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1132 - accuracy: 0.8868\n",
      "Epoch 507/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1131 - accuracy: 0.8868\n",
      "Epoch 508/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1131 - accuracy: 0.8868\n",
      "Epoch 509/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1130 - accuracy: 0.8915\n",
      "Epoch 510/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1129 - accuracy: 0.8915\n",
      "Epoch 511/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1129 - accuracy: 0.8915\n",
      "Epoch 512/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1128 - accuracy: 0.8962\n",
      "Epoch 513/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1128 - accuracy: 0.8962\n",
      "Epoch 514/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1127 - accuracy: 0.8962\n",
      "Epoch 515/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1127 - accuracy: 0.8962\n",
      "Epoch 516/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1126 - accuracy: 0.8962\n",
      "Epoch 517/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1126 - accuracy: 0.8962\n",
      "Epoch 518/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1126 - accuracy: 0.8962\n",
      "Epoch 519/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1125 - accuracy: 0.8962\n",
      "Epoch 520/1000\n",
      "212/212 [==============================] - 0s 90us/step - loss: 0.1125 - accuracy: 0.8962\n",
      "Epoch 521/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1124 - accuracy: 0.8962\n",
      "Epoch 522/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1124 - accuracy: 0.8962\n",
      "Epoch 523/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1123 - accuracy: 0.8962\n",
      "Epoch 524/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1123 - accuracy: 0.8962\n",
      "Epoch 525/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1122 - accuracy: 0.8962\n",
      "Epoch 526/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1122 - accuracy: 0.8962\n",
      "Epoch 527/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1121 - accuracy: 0.8962\n",
      "Epoch 528/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1121 - accuracy: 0.8962\n",
      "Epoch 529/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1120 - accuracy: 0.8962\n",
      "Epoch 530/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1120 - accuracy: 0.8962\n",
      "Epoch 531/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1119 - accuracy: 0.8962\n",
      "Epoch 532/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1119 - accuracy: 0.8962\n",
      "Epoch 533/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1118 - accuracy: 0.8962\n",
      "Epoch 534/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1118 - accuracy: 0.8962\n",
      "Epoch 535/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1117 - accuracy: 0.8962\n",
      "Epoch 536/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1117 - accuracy: 0.8962\n",
      "Epoch 537/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1116 - accuracy: 0.8962\n",
      "Epoch 538/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1116 - accuracy: 0.8962\n",
      "Epoch 539/1000\n",
      "212/212 [==============================] - 0s 92us/step - loss: 0.1115 - accuracy: 0.8962\n",
      "Epoch 540/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1115 - accuracy: 0.8962\n",
      "Epoch 541/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1114 - accuracy: 0.8962\n",
      "Epoch 542/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1114 - accuracy: 0.8962\n",
      "Epoch 543/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1114 - accuracy: 0.8962\n",
      "Epoch 544/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1113 - accuracy: 0.8962\n",
      "Epoch 545/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1113 - accuracy: 0.8962\n",
      "Epoch 546/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1112 - accuracy: 0.8962\n",
      "Epoch 547/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 87us/step - loss: 0.1112 - accuracy: 0.8962\n",
      "Epoch 548/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1111 - accuracy: 0.8962\n",
      "Epoch 549/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1111 - accuracy: 0.8962\n",
      "Epoch 550/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1110 - accuracy: 0.8962\n",
      "Epoch 551/1000\n",
      "212/212 [==============================] - 0s 90us/step - loss: 0.1110 - accuracy: 0.8962\n",
      "Epoch 552/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1109 - accuracy: 0.8962\n",
      "Epoch 553/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1109 - accuracy: 0.9009\n",
      "Epoch 554/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1108 - accuracy: 0.9009\n",
      "Epoch 555/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1108 - accuracy: 0.9009\n",
      "Epoch 556/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1107 - accuracy: 0.9009\n",
      "Epoch 557/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1107 - accuracy: 0.9009\n",
      "Epoch 558/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1106 - accuracy: 0.9009\n",
      "Epoch 559/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1106 - accuracy: 0.9009\n",
      "Epoch 560/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1105 - accuracy: 0.9009\n",
      "Epoch 561/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1105 - accuracy: 0.9009\n",
      "Epoch 562/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1104 - accuracy: 0.9009\n",
      "Epoch 563/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1104 - accuracy: 0.9009\n",
      "Epoch 564/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1104 - accuracy: 0.9009\n",
      "Epoch 565/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1103 - accuracy: 0.9009\n",
      "Epoch 566/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1103 - accuracy: 0.9009\n",
      "Epoch 567/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1102 - accuracy: 0.9009\n",
      "Epoch 568/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1101 - accuracy: 0.9009\n",
      "Epoch 569/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1101 - accuracy: 0.9009\n",
      "Epoch 570/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1101 - accuracy: 0.9009\n",
      "Epoch 571/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1100 - accuracy: 0.9009\n",
      "Epoch 572/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1100 - accuracy: 0.9009\n",
      "Epoch 573/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1099 - accuracy: 0.9009\n",
      "Epoch 574/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1099 - accuracy: 0.9009\n",
      "Epoch 575/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1098 - accuracy: 0.9009\n",
      "Epoch 576/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1098 - accuracy: 0.9009\n",
      "Epoch 577/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1098 - accuracy: 0.9009\n",
      "Epoch 578/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1097 - accuracy: 0.9009\n",
      "Epoch 579/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1096 - accuracy: 0.9009\n",
      "Epoch 580/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1096 - accuracy: 0.9009\n",
      "Epoch 581/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1095 - accuracy: 0.9009\n",
      "Epoch 582/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1095 - accuracy: 0.9009\n",
      "Epoch 583/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1094 - accuracy: 0.9009\n",
      "Epoch 584/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1094 - accuracy: 0.9009\n",
      "Epoch 585/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1094 - accuracy: 0.9009\n",
      "Epoch 586/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1093 - accuracy: 0.9009\n",
      "Epoch 587/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1093 - accuracy: 0.9009\n",
      "Epoch 588/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1092 - accuracy: 0.9009\n",
      "Epoch 589/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1092 - accuracy: 0.9009\n",
      "Epoch 590/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1091 - accuracy: 0.9009\n",
      "Epoch 591/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1091 - accuracy: 0.9009\n",
      "Epoch 592/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1090 - accuracy: 0.9009\n",
      "Epoch 593/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1090 - accuracy: 0.9009\n",
      "Epoch 594/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1089 - accuracy: 0.9009\n",
      "Epoch 595/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1089 - accuracy: 0.9009\n",
      "Epoch 596/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1088 - accuracy: 0.9009\n",
      "Epoch 597/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1088 - accuracy: 0.9009\n",
      "Epoch 598/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1088 - accuracy: 0.9009\n",
      "Epoch 599/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1087 - accuracy: 0.9009\n",
      "Epoch 600/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1087 - accuracy: 0.9009\n",
      "Epoch 601/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1086 - accuracy: 0.9009\n",
      "Epoch 602/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1086 - accuracy: 0.9009\n",
      "Epoch 603/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1085 - accuracy: 0.9009\n",
      "Epoch 604/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1085 - accuracy: 0.9009\n",
      "Epoch 605/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1084 - accuracy: 0.9009\n",
      "Epoch 606/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1084 - accuracy: 0.9057\n",
      "Epoch 607/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1084 - accuracy: 0.9057\n",
      "Epoch 608/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1083 - accuracy: 0.9057\n",
      "Epoch 609/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1083 - accuracy: 0.9057\n",
      "Epoch 610/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1082 - accuracy: 0.9057\n",
      "Epoch 611/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1082 - accuracy: 0.9057\n",
      "Epoch 612/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1081 - accuracy: 0.9057\n",
      "Epoch 613/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1081 - accuracy: 0.9057\n",
      "Epoch 614/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1080 - accuracy: 0.9057\n",
      "Epoch 615/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1080 - accuracy: 0.9057\n",
      "Epoch 616/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1079 - accuracy: 0.9057\n",
      "Epoch 617/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1079 - accuracy: 0.9057\n",
      "Epoch 618/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1079 - accuracy: 0.9057\n",
      "Epoch 619/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1078 - accuracy: 0.9057\n",
      "Epoch 620/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1078 - accuracy: 0.9057\n",
      "Epoch 621/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1077 - accuracy: 0.9057\n",
      "Epoch 622/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1077 - accuracy: 0.9057\n",
      "Epoch 623/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1076 - accuracy: 0.9057\n",
      "Epoch 624/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1076 - accuracy: 0.9057\n",
      "Epoch 625/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 80us/step - loss: 0.1075 - accuracy: 0.9057\n",
      "Epoch 626/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1075 - accuracy: 0.9104\n",
      "Epoch 627/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1075 - accuracy: 0.9104\n",
      "Epoch 628/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1074 - accuracy: 0.9104\n",
      "Epoch 629/1000\n",
      "212/212 [==============================] - 0s 57us/step - loss: 0.1074 - accuracy: 0.9104\n",
      "Epoch 630/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1073 - accuracy: 0.9104\n",
      "Epoch 631/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1073 - accuracy: 0.9104\n",
      "Epoch 632/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1073 - accuracy: 0.9104\n",
      "Epoch 633/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1072 - accuracy: 0.9104\n",
      "Epoch 634/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1072 - accuracy: 0.9104\n",
      "Epoch 635/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1071 - accuracy: 0.9104\n",
      "Epoch 636/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1071 - accuracy: 0.9104\n",
      "Epoch 637/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1071 - accuracy: 0.9104\n",
      "Epoch 638/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1070 - accuracy: 0.9104\n",
      "Epoch 639/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1070 - accuracy: 0.9104\n",
      "Epoch 640/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1070 - accuracy: 0.9104\n",
      "Epoch 641/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.1069 - accuracy: 0.9104\n",
      "Epoch 642/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1069 - accuracy: 0.9104\n",
      "Epoch 643/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1068 - accuracy: 0.9104\n",
      "Epoch 644/1000\n",
      "212/212 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.84 - 0s 66us/step - loss: 0.1068 - accuracy: 0.9104\n",
      "Epoch 645/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1068 - accuracy: 0.9104\n",
      "Epoch 646/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1067 - accuracy: 0.9104\n",
      "Epoch 647/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1067 - accuracy: 0.9104\n",
      "Epoch 648/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1066 - accuracy: 0.9104\n",
      "Epoch 649/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1066 - accuracy: 0.9104\n",
      "Epoch 650/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1066 - accuracy: 0.9104\n",
      "Epoch 651/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1065 - accuracy: 0.9104\n",
      "Epoch 652/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1065 - accuracy: 0.9104\n",
      "Epoch 653/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1065 - accuracy: 0.9104\n",
      "Epoch 654/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1064 - accuracy: 0.9104\n",
      "Epoch 655/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1064 - accuracy: 0.9104\n",
      "Epoch 656/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1063 - accuracy: 0.9104\n",
      "Epoch 657/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1063 - accuracy: 0.9104\n",
      "Epoch 658/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1063 - accuracy: 0.9104\n",
      "Epoch 659/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1062 - accuracy: 0.9104\n",
      "Epoch 660/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1062 - accuracy: 0.9104\n",
      "Epoch 661/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1061 - accuracy: 0.9104\n",
      "Epoch 662/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1061 - accuracy: 0.9104\n",
      "Epoch 663/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1061 - accuracy: 0.9104\n",
      "Epoch 664/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1060 - accuracy: 0.9104\n",
      "Epoch 665/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1060 - accuracy: 0.9104\n",
      "Epoch 666/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1059 - accuracy: 0.9104\n",
      "Epoch 667/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1059 - accuracy: 0.9104\n",
      "Epoch 668/1000\n",
      "212/212 [==============================] - 0s 99us/step - loss: 0.1059 - accuracy: 0.9104\n",
      "Epoch 669/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1058 - accuracy: 0.9104\n",
      "Epoch 670/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1058 - accuracy: 0.9104\n",
      "Epoch 671/1000\n",
      "212/212 [==============================] - 0s 99us/step - loss: 0.1058 - accuracy: 0.9104\n",
      "Epoch 672/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1057 - accuracy: 0.9104\n",
      "Epoch 673/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1057 - accuracy: 0.9104\n",
      "Epoch 674/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1056 - accuracy: 0.9104\n",
      "Epoch 675/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1056 - accuracy: 0.9104\n",
      "Epoch 676/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1056 - accuracy: 0.9104\n",
      "Epoch 677/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1055 - accuracy: 0.9104\n",
      "Epoch 678/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1055 - accuracy: 0.9104\n",
      "Epoch 679/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1054 - accuracy: 0.9104\n",
      "Epoch 680/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1054 - accuracy: 0.9104\n",
      "Epoch 681/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1054 - accuracy: 0.9104\n",
      "Epoch 682/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1053 - accuracy: 0.9104\n",
      "Epoch 683/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1053 - accuracy: 0.9104\n",
      "Epoch 684/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1052 - accuracy: 0.9104\n",
      "Epoch 685/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1052 - accuracy: 0.9104\n",
      "Epoch 686/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1052 - accuracy: 0.9104\n",
      "Epoch 687/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1051 - accuracy: 0.9104\n",
      "Epoch 688/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1051 - accuracy: 0.9104\n",
      "Epoch 689/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1051 - accuracy: 0.9104\n",
      "Epoch 690/1000\n",
      "212/212 [==============================] - 0s 99us/step - loss: 0.1050 - accuracy: 0.9104\n",
      "Epoch 691/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1050 - accuracy: 0.9104\n",
      "Epoch 692/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1049 - accuracy: 0.9104\n",
      "Epoch 693/1000\n",
      "212/212 [==============================] - 0s 92us/step - loss: 0.1049 - accuracy: 0.9104\n",
      "Epoch 694/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1048 - accuracy: 0.9104\n",
      "Epoch 695/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1048 - accuracy: 0.9104\n",
      "Epoch 696/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1048 - accuracy: 0.9104\n",
      "Epoch 697/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1048 - accuracy: 0.9104\n",
      "Epoch 698/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1047 - accuracy: 0.9104\n",
      "Epoch 699/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1047 - accuracy: 0.9104\n",
      "Epoch 700/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1046 - accuracy: 0.9104\n",
      "Epoch 701/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1046 - accuracy: 0.9104\n",
      "Epoch 702/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 73us/step - loss: 0.1046 - accuracy: 0.9104\n",
      "Epoch 703/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1045 - accuracy: 0.9104\n",
      "Epoch 704/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1045 - accuracy: 0.9104\n",
      "Epoch 705/1000\n",
      "212/212 [==============================] - 0s 92us/step - loss: 0.1044 - accuracy: 0.9104\n",
      "Epoch 706/1000\n",
      "212/212 [==============================] - 0s 97us/step - loss: 0.1044 - accuracy: 0.9104\n",
      "Epoch 707/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1044 - accuracy: 0.9104\n",
      "Epoch 708/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1043 - accuracy: 0.9104\n",
      "Epoch 709/1000\n",
      "212/212 [==============================] - 0s 114us/step - loss: 0.1043 - accuracy: 0.9104\n",
      "Epoch 710/1000\n",
      "212/212 [==============================] - 0s 114us/step - loss: 0.1043 - accuracy: 0.9104\n",
      "Epoch 711/1000\n",
      "212/212 [==============================] - 0s 92us/step - loss: 0.1042 - accuracy: 0.9104\n",
      "Epoch 712/1000\n",
      "212/212 [==============================] - 0s 123us/step - loss: 0.1042 - accuracy: 0.9104\n",
      "Epoch 713/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1042 - accuracy: 0.9104\n",
      "Epoch 714/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1041 - accuracy: 0.9104\n",
      "Epoch 715/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1041 - accuracy: 0.9104\n",
      "Epoch 716/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1040 - accuracy: 0.9104\n",
      "Epoch 717/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1040 - accuracy: 0.9104\n",
      "Epoch 718/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1040 - accuracy: 0.9104\n",
      "Epoch 719/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1040 - accuracy: 0.9104\n",
      "Epoch 720/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1039 - accuracy: 0.9104\n",
      "Epoch 721/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1039 - accuracy: 0.9104\n",
      "Epoch 722/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1038 - accuracy: 0.9104\n",
      "Epoch 723/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1038 - accuracy: 0.9104\n",
      "Epoch 724/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1038 - accuracy: 0.9104\n",
      "Epoch 725/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1037 - accuracy: 0.9104\n",
      "Epoch 726/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1037 - accuracy: 0.9104\n",
      "Epoch 727/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1036 - accuracy: 0.9104\n",
      "Epoch 728/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1036 - accuracy: 0.9104\n",
      "Epoch 729/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1036 - accuracy: 0.9104\n",
      "Epoch 730/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1035 - accuracy: 0.9104\n",
      "Epoch 731/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1035 - accuracy: 0.9104\n",
      "Epoch 732/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1035 - accuracy: 0.9104\n",
      "Epoch 733/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1034 - accuracy: 0.9104\n",
      "Epoch 734/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1034 - accuracy: 0.9104\n",
      "Epoch 735/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1034 - accuracy: 0.9104\n",
      "Epoch 736/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1033 - accuracy: 0.9104\n",
      "Epoch 737/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1033 - accuracy: 0.9104\n",
      "Epoch 738/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1033 - accuracy: 0.9104\n",
      "Epoch 739/1000\n",
      "212/212 [==============================] - 0s 92us/step - loss: 0.1032 - accuracy: 0.9104\n",
      "Epoch 740/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1032 - accuracy: 0.9104\n",
      "Epoch 741/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1032 - accuracy: 0.9104\n",
      "Epoch 742/1000\n",
      "212/212 [==============================] - 0s 90us/step - loss: 0.1031 - accuracy: 0.9104\n",
      "Epoch 743/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1031 - accuracy: 0.9104\n",
      "Epoch 744/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1031 - accuracy: 0.9104\n",
      "Epoch 745/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1030 - accuracy: 0.9104\n",
      "Epoch 746/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1030 - accuracy: 0.9104\n",
      "Epoch 747/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1030 - accuracy: 0.9104\n",
      "Epoch 748/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1029 - accuracy: 0.9104\n",
      "Epoch 749/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1029 - accuracy: 0.9104\n",
      "Epoch 750/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1029 - accuracy: 0.9104\n",
      "Epoch 751/1000\n",
      "212/212 [==============================] - 0s 128us/step - loss: 0.1028 - accuracy: 0.9104\n",
      "Epoch 752/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1028 - accuracy: 0.9104\n",
      "Epoch 753/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1028 - accuracy: 0.9104\n",
      "Epoch 754/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1027 - accuracy: 0.9104\n",
      "Epoch 755/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1027 - accuracy: 0.9104\n",
      "Epoch 756/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1027 - accuracy: 0.9104\n",
      "Epoch 757/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1026 - accuracy: 0.9104\n",
      "Epoch 758/1000\n",
      "212/212 [==============================] - 0s 59us/step - loss: 0.1026 - accuracy: 0.9104\n",
      "Epoch 759/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1026 - accuracy: 0.9104\n",
      "Epoch 760/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1025 - accuracy: 0.9104\n",
      "Epoch 761/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1025 - accuracy: 0.9104\n",
      "Epoch 762/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1025 - accuracy: 0.9104\n",
      "Epoch 763/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1024 - accuracy: 0.9104\n",
      "Epoch 764/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1024 - accuracy: 0.9104\n",
      "Epoch 765/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1024 - accuracy: 0.9104\n",
      "Epoch 766/1000\n",
      "212/212 [==============================] - 0s 99us/step - loss: 0.1023 - accuracy: 0.9104\n",
      "Epoch 767/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1023 - accuracy: 0.9104\n",
      "Epoch 768/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1023 - accuracy: 0.9104\n",
      "Epoch 769/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1022 - accuracy: 0.9104\n",
      "Epoch 770/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1022 - accuracy: 0.9104\n",
      "Epoch 771/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1021 - accuracy: 0.9104\n",
      "Epoch 772/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1021 - accuracy: 0.9104\n",
      "Epoch 773/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1021 - accuracy: 0.9104\n",
      "Epoch 774/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1021 - accuracy: 0.9104\n",
      "Epoch 775/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1020 - accuracy: 0.9104\n",
      "Epoch 776/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1020 - accuracy: 0.9104\n",
      "Epoch 777/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1020 - accuracy: 0.9104\n",
      "Epoch 778/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1019 - accuracy: 0.9104\n",
      "Epoch 779/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1019 - accuracy: 0.9104\n",
      "Epoch 780/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.87 - 0s 83us/step - loss: 0.1019 - accuracy: 0.9104\n",
      "Epoch 781/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1018 - accuracy: 0.9104\n",
      "Epoch 782/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1018 - accuracy: 0.9104\n",
      "Epoch 783/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.1018 - accuracy: 0.9104\n",
      "Epoch 784/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1017 - accuracy: 0.9104\n",
      "Epoch 785/1000\n",
      "212/212 [==============================] - 0s 99us/step - loss: 0.1017 - accuracy: 0.9104\n",
      "Epoch 786/1000\n",
      "212/212 [==============================] - 0s 104us/step - loss: 0.1017 - accuracy: 0.9104\n",
      "Epoch 787/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1016 - accuracy: 0.9104\n",
      "Epoch 788/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1016 - accuracy: 0.9104\n",
      "Epoch 789/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1016 - accuracy: 0.9104\n",
      "Epoch 790/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1015 - accuracy: 0.9104\n",
      "Epoch 791/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1015 - accuracy: 0.9104\n",
      "Epoch 792/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1015 - accuracy: 0.9104\n",
      "Epoch 793/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1014 - accuracy: 0.9104\n",
      "Epoch 794/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1014 - accuracy: 0.9104\n",
      "Epoch 795/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1014 - accuracy: 0.9104\n",
      "Epoch 796/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.1013 - accuracy: 0.9104\n",
      "Epoch 797/1000\n",
      "212/212 [==============================] - 0s 59us/step - loss: 0.1013 - accuracy: 0.9104\n",
      "Epoch 798/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.1013 - accuracy: 0.9104\n",
      "Epoch 799/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1012 - accuracy: 0.9104\n",
      "Epoch 800/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1012 - accuracy: 0.9104\n",
      "Epoch 801/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1012 - accuracy: 0.9104\n",
      "Epoch 802/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1012 - accuracy: 0.9104\n",
      "Epoch 803/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1011 - accuracy: 0.9104\n",
      "Epoch 804/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1011 - accuracy: 0.9104\n",
      "Epoch 805/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.1011 - accuracy: 0.9104\n",
      "Epoch 806/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1010 - accuracy: 0.9104\n",
      "Epoch 807/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1010 - accuracy: 0.9104\n",
      "Epoch 808/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1010 - accuracy: 0.9104\n",
      "Epoch 809/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1009 - accuracy: 0.9104\n",
      "Epoch 810/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1009 - accuracy: 0.9104\n",
      "Epoch 811/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1008 - accuracy: 0.9104\n",
      "Epoch 812/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1008 - accuracy: 0.9104\n",
      "Epoch 813/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.1008 - accuracy: 0.9104\n",
      "Epoch 814/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1008 - accuracy: 0.9104\n",
      "Epoch 815/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1007 - accuracy: 0.9104\n",
      "Epoch 816/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.1007 - accuracy: 0.9104\n",
      "Epoch 817/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1007 - accuracy: 0.9104\n",
      "Epoch 818/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1006 - accuracy: 0.9104\n",
      "Epoch 819/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1006 - accuracy: 0.9104\n",
      "Epoch 820/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1006 - accuracy: 0.9104\n",
      "Epoch 821/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1005 - accuracy: 0.9104\n",
      "Epoch 822/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1005 - accuracy: 0.9104\n",
      "Epoch 823/1000\n",
      "212/212 [==============================] - 0s 95us/step - loss: 0.1005 - accuracy: 0.9104\n",
      "Epoch 824/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1004 - accuracy: 0.9104\n",
      "Epoch 825/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1004 - accuracy: 0.9104\n",
      "Epoch 826/1000\n",
      "212/212 [==============================] - 0s 88us/step - loss: 0.1004 - accuracy: 0.9104\n",
      "Epoch 827/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1003 - accuracy: 0.9104\n",
      "Epoch 828/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1003 - accuracy: 0.9104\n",
      "Epoch 829/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1003 - accuracy: 0.9104\n",
      "Epoch 830/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.1003 - accuracy: 0.9104\n",
      "Epoch 831/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.1002 - accuracy: 0.9104\n",
      "Epoch 832/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1002 - accuracy: 0.9104\n",
      "Epoch 833/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1002 - accuracy: 0.9104\n",
      "Epoch 834/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1002 - accuracy: 0.9104\n",
      "Epoch 835/1000\n",
      "212/212 [==============================] - 0s 102us/step - loss: 0.1001 - accuracy: 0.9104\n",
      "Epoch 836/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.1001 - accuracy: 0.9104\n",
      "Epoch 837/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1000 - accuracy: 0.9104\n",
      "Epoch 838/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.1000 - accuracy: 0.9104\n",
      "Epoch 839/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.1000 - accuracy: 0.9104\n",
      "Epoch 840/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.1000 - accuracy: 0.9104\n",
      "Epoch 841/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0999 - accuracy: 0.9104\n",
      "Epoch 842/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0999 - accuracy: 0.9104\n",
      "Epoch 843/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0999 - accuracy: 0.9104\n",
      "Epoch 844/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0998 - accuracy: 0.9104\n",
      "Epoch 845/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0998 - accuracy: 0.9104\n",
      "Epoch 846/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0998 - accuracy: 0.9104\n",
      "Epoch 847/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0998 - accuracy: 0.9104\n",
      "Epoch 848/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0997 - accuracy: 0.9104\n",
      "Epoch 849/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0997 - accuracy: 0.9104\n",
      "Epoch 850/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.0997 - accuracy: 0.9104\n",
      "Epoch 851/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0997 - accuracy: 0.9104\n",
      "Epoch 852/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.0996 - accuracy: 0.9104\n",
      "Epoch 853/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0996 - accuracy: 0.9104\n",
      "Epoch 854/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0996 - accuracy: 0.9104\n",
      "Epoch 855/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0995 - accuracy: 0.9104\n",
      "Epoch 856/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0995 - accuracy: 0.9104\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 71us/step - loss: 0.0995 - accuracy: 0.9104\n",
      "Epoch 858/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0994 - accuracy: 0.9104\n",
      "Epoch 859/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.0994 - accuracy: 0.9104\n",
      "Epoch 860/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0994 - accuracy: 0.9104\n",
      "Epoch 861/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0994 - accuracy: 0.9104\n",
      "Epoch 862/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0993 - accuracy: 0.9104\n",
      "Epoch 863/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0993 - accuracy: 0.9104\n",
      "Epoch 864/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0993 - accuracy: 0.9104\n",
      "Epoch 865/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0992 - accuracy: 0.9104\n",
      "Epoch 866/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0992 - accuracy: 0.9104\n",
      "Epoch 867/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0992 - accuracy: 0.9104\n",
      "Epoch 868/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0992 - accuracy: 0.9104\n",
      "Epoch 869/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0991 - accuracy: 0.9104\n",
      "Epoch 870/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0991 - accuracy: 0.9104\n",
      "Epoch 871/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.0991 - accuracy: 0.9104\n",
      "Epoch 872/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.0990 - accuracy: 0.9104\n",
      "Epoch 873/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.0990 - accuracy: 0.9104\n",
      "Epoch 874/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0990 - accuracy: 0.9104\n",
      "Epoch 875/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0990 - accuracy: 0.9104\n",
      "Epoch 876/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0989 - accuracy: 0.9104\n",
      "Epoch 877/1000\n",
      "212/212 [==============================] - 0s 59us/step - loss: 0.0989 - accuracy: 0.9104\n",
      "Epoch 878/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.0989 - accuracy: 0.9104\n",
      "Epoch 879/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.0989 - accuracy: 0.9104\n",
      "Epoch 880/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0988 - accuracy: 0.9104\n",
      "Epoch 881/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0988 - accuracy: 0.9104\n",
      "Epoch 882/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0988 - accuracy: 0.9104\n",
      "Epoch 883/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0987 - accuracy: 0.9104\n",
      "Epoch 884/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0987 - accuracy: 0.9104\n",
      "Epoch 885/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.0987 - accuracy: 0.9104\n",
      "Epoch 886/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0986 - accuracy: 0.9104\n",
      "Epoch 887/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.0986 - accuracy: 0.9104\n",
      "Epoch 888/1000\n",
      "212/212 [==============================] - 0s 59us/step - loss: 0.0986 - accuracy: 0.9104\n",
      "Epoch 889/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0986 - accuracy: 0.9104\n",
      "Epoch 890/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0985 - accuracy: 0.9104\n",
      "Epoch 891/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.0985 - accuracy: 0.9104\n",
      "Epoch 892/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.0985 - accuracy: 0.9104\n",
      "Epoch 893/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0985 - accuracy: 0.9104\n",
      "Epoch 894/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0984 - accuracy: 0.9104\n",
      "Epoch 895/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0984 - accuracy: 0.9104\n",
      "Epoch 896/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0984 - accuracy: 0.9104\n",
      "Epoch 897/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0984 - accuracy: 0.9104\n",
      "Epoch 898/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0983 - accuracy: 0.9104\n",
      "Epoch 899/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0983 - accuracy: 0.9104\n",
      "Epoch 900/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0983 - accuracy: 0.9104\n",
      "Epoch 901/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0982 - accuracy: 0.9104\n",
      "Epoch 902/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0982 - accuracy: 0.9104\n",
      "Epoch 903/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0982 - accuracy: 0.9104\n",
      "Epoch 904/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0982 - accuracy: 0.9104\n",
      "Epoch 905/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.0981 - accuracy: 0.9104\n",
      "Epoch 906/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0981 - accuracy: 0.9104\n",
      "Epoch 907/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0981 - accuracy: 0.9104\n",
      "Epoch 908/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0981 - accuracy: 0.9104\n",
      "Epoch 909/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0980 - accuracy: 0.9104\n",
      "Epoch 910/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.0980 - accuracy: 0.9104\n",
      "Epoch 911/1000\n",
      "212/212 [==============================] - 0s 54us/step - loss: 0.0980 - accuracy: 0.9104\n",
      "Epoch 912/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.0980 - accuracy: 0.9104\n",
      "Epoch 913/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0979 - accuracy: 0.9104\n",
      "Epoch 914/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0979 - accuracy: 0.9104\n",
      "Epoch 915/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0979 - accuracy: 0.9104\n",
      "Epoch 916/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.0978 - accuracy: 0.9104\n",
      "Epoch 917/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.0978 - accuracy: 0.9104\n",
      "Epoch 918/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0978 - accuracy: 0.9104\n",
      "Epoch 919/1000\n",
      "212/212 [==============================] - 0s 61us/step - loss: 0.0978 - accuracy: 0.9104\n",
      "Epoch 920/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0977 - accuracy: 0.9104\n",
      "Epoch 921/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.0977 - accuracy: 0.9104\n",
      "Epoch 922/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0977 - accuracy: 0.9104\n",
      "Epoch 923/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.0977 - accuracy: 0.9151\n",
      "Epoch 924/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0976 - accuracy: 0.9151\n",
      "Epoch 925/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0976 - accuracy: 0.9151\n",
      "Epoch 926/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.0976 - accuracy: 0.9151\n",
      "Epoch 927/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0976 - accuracy: 0.9151\n",
      "Epoch 928/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0975 - accuracy: 0.9151\n",
      "Epoch 929/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0975 - accuracy: 0.9151\n",
      "Epoch 930/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0975 - accuracy: 0.9151\n",
      "Epoch 931/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0975 - accuracy: 0.9151\n",
      "Epoch 932/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0974 - accuracy: 0.9151\n",
      "Epoch 933/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0974 - accuracy: 0.9151\n",
      "Epoch 934/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.0974 - accuracy: 0.9151\n",
      "Epoch 935/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/212 [==============================] - 0s 87us/step - loss: 0.0973 - accuracy: 0.9151\n",
      "Epoch 936/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0973 - accuracy: 0.9151\n",
      "Epoch 937/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0973 - accuracy: 0.9151\n",
      "Epoch 938/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.0973 - accuracy: 0.9151\n",
      "Epoch 939/1000\n",
      "212/212 [==============================] - 0s 102us/step - loss: 0.0973 - accuracy: 0.9151\n",
      "Epoch 940/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0972 - accuracy: 0.9151\n",
      "Epoch 941/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0972 - accuracy: 0.9151\n",
      "Epoch 942/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0972 - accuracy: 0.9151\n",
      "Epoch 943/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0971 - accuracy: 0.9151\n",
      "Epoch 944/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0971 - accuracy: 0.9151\n",
      "Epoch 945/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0971 - accuracy: 0.9151\n",
      "Epoch 946/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0971 - accuracy: 0.9151\n",
      "Epoch 947/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0970 - accuracy: 0.9151\n",
      "Epoch 948/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.0970 - accuracy: 0.9151\n",
      "Epoch 949/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.0970 - accuracy: 0.9151\n",
      "Epoch 950/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0970 - accuracy: 0.9151\n",
      "Epoch 951/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0969 - accuracy: 0.9151\n",
      "Epoch 952/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0969 - accuracy: 0.9151\n",
      "Epoch 953/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0969 - accuracy: 0.9151\n",
      "Epoch 954/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0969 - accuracy: 0.9151\n",
      "Epoch 955/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0968 - accuracy: 0.9151\n",
      "Epoch 956/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0968 - accuracy: 0.9151\n",
      "Epoch 957/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0968 - accuracy: 0.9151\n",
      "Epoch 958/1000\n",
      "212/212 [==============================] - 0s 64us/step - loss: 0.0968 - accuracy: 0.9151\n",
      "Epoch 959/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0967 - accuracy: 0.9151\n",
      "Epoch 960/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0967 - accuracy: 0.9151\n",
      "Epoch 961/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0967 - accuracy: 0.9151\n",
      "Epoch 962/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0967 - accuracy: 0.9151\n",
      "Epoch 963/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0967 - accuracy: 0.9198\n",
      "Epoch 964/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0966 - accuracy: 0.9151\n",
      "Epoch 965/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0966 - accuracy: 0.9151\n",
      "Epoch 966/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0966 - accuracy: 0.9198\n",
      "Epoch 967/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0966 - accuracy: 0.9151\n",
      "Epoch 968/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0965 - accuracy: 0.9198\n",
      "Epoch 969/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0965 - accuracy: 0.9198\n",
      "Epoch 970/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0965 - accuracy: 0.9198\n",
      "Epoch 971/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0965 - accuracy: 0.9198\n",
      "Epoch 972/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0964 - accuracy: 0.9198\n",
      "Epoch 973/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0964 - accuracy: 0.9198\n",
      "Epoch 974/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0964 - accuracy: 0.9198\n",
      "Epoch 975/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0964 - accuracy: 0.9198\n",
      "Epoch 976/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0963 - accuracy: 0.9198\n",
      "Epoch 977/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0963 - accuracy: 0.9198\n",
      "Epoch 978/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0963 - accuracy: 0.9198\n",
      "Epoch 979/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0963 - accuracy: 0.9198\n",
      "Epoch 980/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0962 - accuracy: 0.9198\n",
      "Epoch 981/1000\n",
      "212/212 [==============================] - 0s 92us/step - loss: 0.0962 - accuracy: 0.9198\n",
      "Epoch 982/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.0962 - accuracy: 0.9198\n",
      "Epoch 983/1000\n",
      "212/212 [==============================] - 0s 69us/step - loss: 0.0962 - accuracy: 0.9198\n",
      "Epoch 984/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0961 - accuracy: 0.9198\n",
      "Epoch 985/1000\n",
      "212/212 [==============================] - 0s 83us/step - loss: 0.0961 - accuracy: 0.9198\n",
      "Epoch 986/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0961 - accuracy: 0.9198\n",
      "Epoch 987/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0961 - accuracy: 0.9198\n",
      "Epoch 988/1000\n",
      "212/212 [==============================] - 0s 85us/step - loss: 0.0960 - accuracy: 0.9198\n",
      "Epoch 989/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0960 - accuracy: 0.9198\n",
      "Epoch 990/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0960 - accuracy: 0.9198\n",
      "Epoch 991/1000\n",
      "212/212 [==============================] - 0s 78us/step - loss: 0.0960 - accuracy: 0.9198\n",
      "Epoch 992/1000\n",
      "212/212 [==============================] - 0s 87us/step - loss: 0.0960 - accuracy: 0.9198\n",
      "Epoch 993/1000\n",
      "212/212 [==============================] - 0s 73us/step - loss: 0.0959 - accuracy: 0.9198\n",
      "Epoch 994/1000\n",
      "212/212 [==============================] - 0s 80us/step - loss: 0.0959 - accuracy: 0.9198\n",
      "Epoch 995/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.0959 - accuracy: 0.9198\n",
      "Epoch 996/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0958 - accuracy: 0.9198\n",
      "Epoch 997/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0958 - accuracy: 0.9198\n",
      "Epoch 998/1000\n",
      "212/212 [==============================] - 0s 71us/step - loss: 0.0958 - accuracy: 0.9198\n",
      "Epoch 999/1000\n",
      "212/212 [==============================] - 0s 66us/step - loss: 0.0958 - accuracy: 0.9198\n",
      "Epoch 1000/1000\n",
      "212/212 [==============================] - 0s 76us/step - loss: 0.0957 - accuracy: 0.9198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89.01098901098901"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=1000)\n",
    "\n",
    "Y_pred_NN = model.predict(X_test)\n",
    "rounded = [round(x[0]) for x in Y_pred_NN]\n",
    "\n",
    "Y_pred_NN = rounded\n",
    "\n",
    "NNscore = accuracy_score(Y_pred_NN,Y_test)*100\n",
    "NNscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score achieved using Logistic Regression is: 81.31868131868131 %\n",
      "The accuracy score achieved using Naive Bayes is: 80.21978021978022 %\n",
      "The accuracy score achieved using Support Vector Machine is: 80.21978021978022 %\n",
      "The accuracy score achieved using K-Nearest Neighbors is: 81.31868131868131 %\n",
      "The accuracy score achieved using Decision Tree is: 75.82417582417582 %\n",
      "The accuracy score achieved using Random Forest is: 84.61538461538461 %\n",
      "The accuracy score achieved using XGBoost is: 80.21978021978022 %\n",
      "The accuracy score achieved using Neural Network is: 89.01098901098901 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = [LogRegscore,NBscore,SVMscore,KNNscore,DTscore,RFscore,XGBscore,NNscore]\n",
    "algorithms = [\"Logistic Regression\",\"Naive Bayes\",\"Support Vector Machine\",\"K-Nearest Neighbors\",\"Decision Tree\",\"Random Forest\",\"XGBoost\",\"Neural Network\"]    \n",
    "\n",
    "for i in range(len(algorithms)):\n",
    "    print(\"The accuracy score achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18e485a1e08>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAHiCAYAAABLBzXPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeYCNdf//8deZ1a5pjKWUKFEUSpYsNdYYM1ODknu4dVdSlpI1JgmJEe4Q9526KxK3nRCJkAyitNxEhaI0xr6M2c75/P7wm/M1zDhnmDMzfTwff825zrk+1/tcn2t7nWsZhzHGCAAAAADwl+ZX0AUAAAAAAK4e4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACwQUNAF5Nbx42flcvHfGwAAAABcW/z8HAoJKZ7j+3+5cOdyGcIdAAAAAFyEyzIBAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsEBAQRcAAAAA4K+ndOkiCgoKLOgyrJGWlq6TJ1Ouqg3CHQAAAIBcCwoK1Pjx4wu6DGv069dP0tWFOy7LBAAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMACAQVdAAAAQEEoXSpIQcHBBV2GFdJSU3XyVFpBlwFc8wh3AADgmhQUHKwJLz1T0GVY4cXX/y2JcAcUNC7LBAAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAIBBV2Ar5QsVURFggMLugwrpKSm6/SplIIuA8AFrisZpMAiwQVdhjXSU1J14nRaQZcBAMBVsTbcFQkOVOeBswq6DCt8FP83nRbhDihMAosEa0XXJwq6DGu0nfGeRLgDAPzFcVkmAAAAAFjAp+FuyZIlioiIUEREhMaOHStJ2rVrl2JiYtS6dWsNHTpUGRkZviwBAAAAAK4JPgt3586d02uvvaaZM2dqyZIl2rZtmzZt2qQBAwZo2LBhWrVqlYwxmjt3rq9KAAAAAIBrhs/uuXM6nXK5XDp37pyKFSumjIwMBQQEKCUlRbVr15YkxcTEaNKkSercubOvykAhFVI6SAFBPAwir2Skper4yby9X6hU6WAFBwXlaZvXqtS0NJ06mVrQZQDAX0pI6aIKCLL28RD5LiMtQ8dPnivoMuBjPltjSpQooeeff15t2rRR0aJFdd999ykwMFBhYWHuz4SFhSkxMTFX7YaGlsjrUuGFsLCSed7m9vin8rzNa9W9A99RWFjeh+Vu7z2f521ei95/4k2FhRGUCztfbOeAa4kv1qFvp67L8zavVbWee5Dt3F/A1faRz8Ldjz/+qAULFujzzz9XyZIl1b9/f3355ZdyOBzuzxhjsrz2xtGjZ+RyGY+fY+HNW0lJp/O0Pfon79FHhRv9U/jldR+h8GM9ylts5wo/+qjw89RHfn6Oy57s8tk9dxs3blTDhg0VGhqqoKAgxcTEaMuWLUpKSnJ/5siRIypbtqyvSgAAAACAa4bPwl316tW1adMmJScnyxijtWvXql69egoODtb27dslnX+aZtOmTX1VAgAAAABcM3x2WWbjxo21c+dOxcTEKDAwUHfddZe6d++uli1bKi4uTmfOnFGNGjXUtWtXX5UAAAAAANcMnz6CqHv37urevXuWYdWrV9f8+fN9OVkAAAAAuOb49J+YAwAAAADyB+EOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwQEBBFwAAgI1KlyqqoGB2s3klLTVDJ0+dK+gyAKBQY68DAIAPBAUHaPTQ+QVdhjWGvNahoEsAgEKPyzIBAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAj4Nd2vXrlVMTIzatGmjUaNGSZI2bdqkyMhItWrVShMnTvTl5AEAAADgmuGzcHfgwAG98sormjp1qpYuXaqdO3dq/fr1GjJkiKZOnaoVK1bohx9+0Pr1631VAgAAAABcM3wW7lavXq22bduqfPnyCgwM1MSJE1W0aFFVqlRJN910kwICAhQZGamVK1f6qgQAAAAAuGYE+KrhX3/9VYGBgerRo4cOHTqkBx98UFWrVlVYWJj7M2XLllViYmKu2g0NLZHXpcILYWElC7oEeEAfFW70T+FHHxV+9FHhRv8UfvRR4Xe1feSzcOd0OrVt2zbNnDlTxYoV07PPPqsiRYrI4XC4P2OMyfLaG0ePnpHLZTx+joU3byUlnc7T9uifvEcfFW70T+FHHxV+9FHhRv8UfvRR4eepj/z8HJc92eWzcFemTBk1bNhQ119/vSSpRYsWWrlypfz9/d2fSUpKUtmyZX1VAgAAAABcM3x2z114eLg2btyoU6dOyel06osvvtBDDz2kffv26ddff5XT6dSyZcvUtGlTX5UAAAAAANcMn525q1Wrlp566il17txZ6enpatSokR5//HFVqVJFvXv3Vmpqqh544AE99NBDvioBAAAAAK4ZPgt3ktShQwd16NAhy7CGDRtq6dKlvpwsAAAAAFxzfPpPzAEAAAAA+YNwBwAAAAAWINwBAAAAgAUIdwAAAABgAcIdAAAAAFiAcAcAAAAAFiDcAQAAAIAFCHcAAAAAYAHCHQAAAABYgHAHAAAAABYg3AEAAACABQh3AAAAAGABwh0AAAAAWIBwBwAAAAAWINwBAAAAgAUIdwAAAABgAcIdAAAAAFjAq3C3cuVKTZw4UefOndOyZct8XRMAAAAAIJc8hru3335bs2fP1sqVK5WSkqIpU6borbfeyo/aAAAAAABe8hjuli9frunTp6to0aIKCQnR3LlzOXsHAAAAAIWMx3AXEBCgoKAg9+tSpUopICDAp0UBAAAAAHLHY0qrUKGC1q1bJ4fDobS0NL377ru68cYb86M2AAAAAICXPIa7l19+WQMHDtTu3btVu3Zt1apVS+PHj8+P2gAAAAAAXvIY7r7//nt98MEHOnfunJxOp0qUKJEfdQEAAAAAcsHjPXcTJ06UJBUtWpRgBwAAAACFlMczd7fffrumTZumunXrqlixYu7hNWrU8GlhAAAAAADveQx33377rb799lvNmzfPPczhcGjNmjU+LQwAAAAA4D2P4W7t2rX5UQcAAAAA4Cp4DHfJycmKj4/Xhg0blJGRoUaNGmno0KHcfwcAAAAAhYjHB6q8/vrrSktL01tvvaWpU6fK4XBo5MiR+VEbAAAAAMBLXt1zt3TpUvfrUaNGKSIiwqdFAQAAAAByx+OZO6fTKZfL5X7tcrnk7+/v06IAAAAAALnj8cxdw4YN9cILL+jxxx+XJM2ePVv16tXzeWEAAAAAAO95DHeDBw/WtGnTNGHCBDmdTjVt2lTPPvtsftQGAAAAAPCSx3AnSZUqVdK8efOUlJSk5cuXKzAw0Nd1AQAAAAByweM9d8OHD9e6devOf9jPT9u3b9fo0aN9XRcAAAAAIBc8nrnbsWOHli1bJkkKDQ3Vm2++qejoaJ8XBgAAAADwnsczd+np6UpLS3O/zsjI8GlBAAAAAIDc83jm7sEHH9STTz6p6OhoORwOLVu2TA888EB+1AYAAAAA8JLHcDdw4EDNmjVLa9asUUBAgFq2bKlOnTrlR20AAAAAAC95DHf+/v7q2rWrunbtqsTERB04cEB+fh6v5gQAAAAA5COPKe2jjz5Sv379dOzYMcXExGjo0KEaP358ftQGAAAAAPCSx3A3f/58vfTSS1q5cqWaNWum5cuX68svv8yP2gAAAAAAXvIY7hwOh8qUKaOEhAQ1bNhQAQEBcrlc+VEbAAAAAMBLHsNdUFCQpk+frq1bt6pRo0b66KOPVLRo0fyoDQAAAADgJY/h7rXXXtP+/fs1duxYlS5dWtu3b9drr72WH7UBAAAAALzk8WmZVapUyRLmeJgKAAAAABQ+/E8DAAAAALAA4Q4AAAAALOAx3B0/fjw/6gAAAAAAXAWP4S4iIkL9+vXTtm3b8qMeAAAAAMAV8Bju1q5dq/vvv1/x8fGKjIzUrFmzdObMmfyoDQAAAADgJY/hrkiRImrfvr3mzp2ruLg4/ec//1GTJk306quvcskmAAAAABQSXj1QZcOGDerdu7f69u2rFi1aaM6cOapQoYKee+45X9cHAAAAAPCCx/9zFx4eruuuu06dO3fWuHHjVKRIEUlStWrV9N///tfnBQIAAAAAPPMY7saPH69q1aqpePHiSktL09GjRxUaGipJWrNmjc8LBAAAAAB45vGyzD///FOPPPKIJOn3339XRESE1q5d6/PCAAAAAADe8xju/vWvf2nGjBmSpMqVK2vRokWaPHmyzwsDAAAAAHjPY7hzuVwqX768+3WFChXkcrl8WhQAAAAAIHc8hrvrr79ec+bMUUZGhpxOp+bPn68yZcrkR20AAAAAAC95DHcjRozQ3Llzdffdd+vuu+/W3Llz9corr+RHbQAAAAAAL3l8WuYtt9yihQsX6uTJk/L391eJEiXyoy4AAAAAQC54DHfHjh3T0qVLdfbsWRlj5HK59Ouvv2r8+PH5UR8AAAAAwAsew90LL7ygIkWK6Oeff9b999+vTZs26d57782P2gAAAAAAXvJ4z90ff/yht99+W02bNlVsbKxmz56tvXv35kdtAAAAAAAveQx3mU/GvOWWW7Rnzx6VK1dOGRkZPi8MAAAAAOA9j5dlhoaG6p133lHt2rU1efJklShRQikpKflRGwAAAADAS179K4SgoCDVrVtXNWvW1KRJk9S/f//8qA0AAAAA4CWPZ+7Gjh2r+Ph4SdKAAQM0YMAAnxcFAAAAAMgdj2fudu3aJWNMftQCAAAAALhCHs/clS1bVhEREapVq5aKFy/uHh4XF+fTwgAAAAAA3vMY7urUqaM6derkRy0AAAAAgCvkMdz16tUrP+oAAAAAAFwFj+EuMjIy2+Eff/xxnhcDAAAAALgyHsPdyy+/7P47PT1dy5cv10033eTTogAAAAAAueMx3NWrVy/L6/vvv1+dOnXSs88+67OiAAAAAAC54/FfIVzs+PHjOnz4sC9qAQAAAABcoVzfc/fHH3/oscce81lBAAAAAIDcy9U9dw6HQ9dff71uvfVWnxYFAAAAAMgdj5dl3nzzzVqxYoXq1aun0NBQjR8/XkeOHMmP2gAAAAAAXvIY7gYPHqwqVapIkm688UbVq1dPL730ks8LAwAAAAB4z2O4O378uLp27SpJCg4OVrdu3ZSUlOTzwgAAAAAA3vMY7pxOpxITE92vjxw5ImOMT4sCAAAAAOSOxweqdOvWTQ8//LCaNGkih8OhTZs2aeDAgflRGwAAAADASx7DXYcOHVSzZk1t3rxZ/v7+euqpp1S1alWvJzB27FgdP35cY8aM0a5duzR06FCdPXtWdevW1auvvqqAAI8lAAAAAAA88HhZZmJioubMmaNu3bqpUaNGmjhxotf33CUkJGjRokXu1wMGDNCwYcO0atUqGWM0d+7cK68cAAAAAODmMdwNGjTokqdlDhkyxGPDJ06c0MSJE9WjRw9J0u+//66UlBTVrl1bkhQTE6OVK1deTe0AAAAAgP/P4zWR2T0tc/HixR4bHjZsmPr27atDhw5Jkg4fPqywsDD3+2FhYVke1OKt0NASuR4HVy8srGRBlwAP6KPCjf4p/Oijwo8+Ktzon8KPPir8rraPPIa7zKdllitXTpJ3T8ucN2+eKlSooIYNG2rhwoWSJJfLJYfD4f6MMSbLa28dPXpGLpfnp3Wy8OatpKTTedoe/ZP36KPCjf4p/Oijwo8+Ktzon8KPPir8PPWRn5/jsie7cvW0TOn8fXSenpa5YsUKJSUlKTo6WidPnlRycrIcDkeWe/WOHDmismXLepo8AAAAAMALuX5a5s0336wZM2YoMjIyx3Hee+89998LFy7U1q1b9frrr6tdu3bavn277r33Xi1ZskRNmzbNm28BAAAAANc4r/4PQYUKFZSWlqZZs2YpOTlZXbp0uaKJvfHGG4qLi9OZM2dUo0YN9718AAAAAICrc9lwt3fvXn3wwQdaunSpbrzxRqWkpGjt2rUqWdL762tjYmIUExMjSapevbrmz59/dRUDAAAAAC6R479C6N69u2JjYxUYGKgZM2Zo2bJlKl68eK6CHQAAAAAgf+QY7nbu3KkaNWqoatWqqlSpkiRd0dMtAQAAAAC+l2O4W7dunR555BEtW7ZMjRs3Vp8+fZSampqftQEAAAAAvJRjuAsICFDbtm01c+ZMLVy4UGXLllVqaqpatWql2bNn52eNAAAAAAAPcgx3F7rtttsUFxenDRs26Mknn9TcuXN9XRcAAAAAIBe8CneZihYtqscee0yLFi3yVT0AAAAAgCuQq3AHAAAAACicCHcAAAAAYAHCHQAAAABYgHAHAAAAABYg3AEAAACABQh3AAAAAGABwh0AAAAAWIBwBwAAAAAWINwBAAAAgAUIdwAAAABgAcIdAAAAAFiAcAcAAAAAFiDcAQAAAIAFCHcAAAAAYAHCHQAAAABYgHAHAAAAABYg3AEAAACABQh3AAAAAGABwh0AAAAAWIBwBwAAAAAWINwBAAAAgAUIdwAAAABgAcIdAAAAAFiAcAcAAAAAFiDcAQAAAIAFCHcAAAAAYAHCHQAAAABYgHAHAAAAABYg3AEAAACABQh3AAAAAGABwh0AAAAAWIBwBwAAAAAWINwBAAAAgAUIdwAAAABgAcIdAAAAAFiAcAcAAAAAFiDcAQAAAIAFCHcAAAAAYAHCHQAAAABYgHAHAAAAABYg3AEAAACABQh3AAAAAGABwh0AAAAAWIBwBwAAAAAWINwBAAAAgAUIdwAAAABgAcIdAAAAAFiAcAcAAAAAFiDcAQAAAIAFCHcAAAAAYAHCHQAAAABYgHAHAAAAABYg3AEAAACABQh3AAAAAGABwh0AAAAAWIBwBwAAAAAWINwBAAAAgAUIdwAAAABgAcIdAAAAAFiAcAcAAAAAFiDcAQAAAIAFCHcAAAAAYAHCHQAAAABYgHAHAAAAABYg3AEAAACABQh3AAAAAGABwh0AAAAAWIBwBwAAAAAWINwBAAAAgAUIdwAAAABgAcIdAAAAAFiAcAcAAAAAFiDcAQAAAIAFCHcAAAAAYAHCHQAAAABYgHAHAAAAABYg3AEAAACABQh3AAAAAGABn4a7KVOmKCIiQhEREYqPj5ckbdq0SZGRkWrVqpUmTpzoy8kDAAAAwDXDZ+Fu06ZN2rhxoxYtWqTFixfrf//7n5YtW6YhQ4Zo6tSpWrFihX744QetX7/eVyUAAAAAwDXDZ+EuLCxMgwcPVlBQkAIDA3Xrrbdq//79qlSpkm666SYFBAQoMjJSK1eu9FUJAAAAAHDNCPBVw1WrVnX/vX//fn3yySeKjY1VWFiYe3jZsmWVmJiYq3ZDQ0vkWY3wXlhYyYIuAR7QR4Ub/VP40UeFH31UuNE/hR99VPhdbR/5LNxl+umnn/TMM89o4MCB8vf31/79+93vGWPkcDhy1d7Ro2fkchmPn2PhzVtJSafztD36J+/RR4Ub/VP40UeFH31UuNE/hR99VPh56iM/P8dlT3b59IEq27dvV7du3dSvXz898sgjKl++vJKSktzvJyUlqWzZsr4sAQAAAACuCT4Ld4cOHVLPnj31xhtvKCIiQpJUq1Yt7du3T7/++qucTqeWLVumpk2b+qoEAAAAALhm+OyyzHfffVepqakaM2aMe1inTp00ZswY9e7dW6mpqXrggQf00EMP+aoEAAAAALhm+CzcxcXFKS4uLtv3li5d6qvJAgAAAMA1yaf33AEAAAAA8gfhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMAChDsAAAAAsADhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALAA4Q4AAAAALEC4AwAAAAALEO4AAAAAwAKEOwAAAACwAOEOAAAAACxAuAMAAAAACxDuAAAAAMACBRLuPv74Y7Vt21atWrXSrFmzCqIEAAAAALBKQH5PMDExURMnTtTChQsVFBSkTp06qX79+rrtttvyuxQAAAAAsEa+h7tNmzapQYMGuu666yRJrVu31sqVK9WrVy+vxvfzc3g9rTIhxa+oRlwqN/PdW0GlQvO8zWuZL/qoTInr87zNa5Uv+qdoGdahvOSLPip9XbE8b/Na5os+KnUd61Fe8UX/BJYskudtXst8sg6VKpXnbV7LPPWRp/cdxhiTlwV58u9//1vJycnq27evJGnevHn67rvvNHLkyPwsAwAAAACsku/33LlcLjkc/5c4jTFZXgMAAAAAci/fw1358uWVlJTkfp2UlKSyZcvmdxkAAAAAYJV8D3f333+/EhISdOzYMZ07d06ffvqpmjZtmt9lAAAAAIBV8v2BKuXKlVPfvn3VtWtXpaenq0OHDrr77rvzuwwAAAAAsEq+P1AFAAAAAJD3CuSfmAMAAAAA8hbhDgAAAAAsQLgDAAAAAAsQ7gAAAADAAoQ7AAAAALDAXzrcbdmyRV26dMmTtqKjoy/7/oXT8fTZCzVr1kxt27ZVdHS0oqOj1axZM/Xp00fJyclXXGteSkxM1NNPP13QZVzWwYMHVa1aNX355ZdZhjdr1kwHDx7Mcby8+m7VqlVz91/btm01dOhQpaamXnW7vrRy5UrFxMQoKipKkZGReueddwqsls8//1zvvfdelmFnzpxRnTp1lJiYmGX41q1b9cgjj+R6Gt99953GjRt3xTUuXLhQ1apV07Jly7IMf//991WtWrXLLmc5GTx4sBYuXHjJ8NmzZ2v27NmXHffibduZM2f06KOPasyYMZd89krXD1+ZO3fuJfNRkiZPnqzWrVsrJSXFPcybbbg38yun79qlSxdt2bLFy8rz38GDB1WzZk339qV169Z66aWXdOTIkStq780339SaNWtyfH/o0KH6/vvvr7RcSdKCBQvc9dasWdO9f3v11Vevqt3C4uI+iYyMVLNmzTRp0qQ8aX/hwoUaPHhwnrR1YZv16tVz1xwdHa0nn3wyT6dxoavd3hakLVu2qHHjxjp69Kh72DvvvKPevXtLkhISEhQbG6vWrVurZcuW6tOnj/7880/3uHXq1FF0dLSioqLUpk0bffDBB3la3+nTp9WzZ888bTO/FdQ+6eDBg2rWrNklw6903+OL5Xzy5MmaPHlynraZnXz/P3eF1ZIlSy77/tatW73+7MXefvttVaxYUZKUlpamzp07a/HixercuXPuC81j5cqV0/Tp0wu6DI8CAwP18ssva+nSpSpRooRX4+Tld8vsc2OMevfurfnz5+tvf/tbnrSd1yvgcVkAACAASURBVBITEzV27FgtXLhQISEhOnv2rLp06aLKlSurefPm+V7PDz/8cMmwEiVKqGXLllq+fLn+8Y9/uIcvXrxYHTp0yPU0fv755yw76ytRvnx5rVq1Su3atXMPW716tUqVKnVV7V7s8ccfz9Xnz549q6eeekr16tVT//79s/3MlawfvvL111+rXr162b73+++/a8KECRoyZIjX7eV2fv3VlC1bNsv2ZcKECerTp48++uijXLf1/PPPX/b911577YpqvFD79u3Vvn17SecP1i7cv9niwj6Rzm9TW7durYiICN16660FWFnOmjVrlu2PP76QF9vbglK/fn1FRkYqLi5O06ZN0zfffKO5c+dq/vz52rZtmwYMGKApU6aodu3akqRZs2apZ8+eWrBggSSpZs2amjlzpqTzP7pFRESoUaNGuu222/KkvpMnT2rXrl150lZBKkz7JOnK9j1/5eXc2nD3r3/9S0uXLpW/v78aNWqkAQMGyN/fXzNmzNCHH36okiVLqkqVKrr55pvVu3dvVatWTbt371ZCQoI7qZcuXVrjx4/X1KlTJUkdO3bUvHnz3J89ceKEhg4dqr179yooKEiDBw9Ww4YNL1vX6dOndfr0aV133XWSpA0bNmjSpEnKyMhQxYoVNXLkSIWEhGjLli0aNWqU/P39Vbt2bf3yyy+aOXOmunTpotKlS+unn37SP//5TyUlJWU7/tixY/Xll1/Kz89PLVq0UK9evbL9bsnJyeratavWrl2rI0eOaOjQofrjjz8UEBCgvn37qmnTppo8ebISExP166+/6vfff1fHjh317LPP+rD3LlW2bFndf//9Gjt2rEaOHJnlvYyMDA0fPlw//fSTjhw5omrVqmnChAk6cuSIunbtqgULFqhdu3Zat26dAgMDtWfPHvXv319Lly7V4sWL9cEHH8jlcqlGjRp65ZVXFBwcnGMd6enpOnfunMqUKSNJ2rNnj0aOHKnk5GQdO3ZM3bt312OPPaYWLVro3XffVeXKlZWcnKw2bdro008/1ZYtW7zuryt1/Phxpaenu3+lKl68uMaMGeP+Xs2aNdOMGTNUsWJFbdmyRVOmTHEvW9WrV9e2bduUmpqqIUOGqHHjxho8eLCCg4P1/fff6+zZs3r22Wf18MMP69y5c4qLi9Pu3bvlcDj05JNP6uGHH9bChQu1aNEinThxQpUqVdI333wjSbrhhhvcB4WSFBMTo/j4eHe4S01N1bp16zRo0CBJyrFvPv74Y02bNk0Oh0N33XWXBg4cqEmTJik5OVnTpk3TM888o9GjRyshIUEOh0NRUVHq3r27tmzZonHjxsnlcqlq1aoaO3Zslvl23333afv27UpOTlaxYsX0xx9/qHjx4ipZsuRll7MiRYro/fff1+zZs+Xv76/w8HANGDBAkrRu3Tp99NFHOnr0qHr06KHHHnvM/atd79691bhxY7Vu3Vrbt2+Xv7+//vnPf+qmm27S3r17tXPnTkVHR+uPP/5QZGRkjsFOuvz6IZ3/gemTTz6R0+lU48aNNWDAADkcDk2cOFEJCQk6efKkypYtq4kTJ6pMmTJq0KCBatasqaSkJM2fP1/vvffeJeOfPXtWL774ovssU8+ePVW0aFGtXbtWmzdvVlhYmJo0aZKljscee0wrVqxQq1atVLdu3SzvHTlyRMOGDdOff/4ph8Ohfv366f77788yv1asWKFJkyapWLFiuuOOO+R0Ot0HtG+99ZZ27dqlc+fOKT4+XrVq1ZJ0/kzi66+/Lkl66aWXVL9+fa+W3fDwcFWtWlXvvPOO/P39VbFiRY0bN+6y24er5XA41Lt3bzVq1Eg//vijqlevnmPfZbfMDR48WPXq1VOrVq0u6ZvmzZurS5cu6tWrl+rXr5/tPvLQoUPq1auXqlatql27dik0NFRvvvmme3/lycXr2LBhwzRixAj99NNPcjqdevrpp9WuXTs5nU7Fx8dr69atcjqdiomJUbdu3Xw2X69WUlKSjDEqXrz4Zfc3Oc27xYsXa9q0aSpRooRuvPFGFStWTJK0Y8cOvfbaa0pNTVVISIhGjBihSpUqqUuXLrrzzju1fft2paamqn///poxY4Z++eUXdevWLVfz6nLTuJJjia5du2bZ3ub3sUBe6Nu3rzp27Og+Hhw7dqxKlSqlqVOn6tlnn3UHO0n629/+ppSUFKWlpV3STmpqqvz9/d37iJzm9b59+zRs2DCdOHFCxYoV09ChQ3X33Xfr448/vmT7MmrUKB0+fFg9e/bUW2+9lW/zJK9dyT7p999/dx+PSsqy7b94n/Tqq69esg5eTm73PTVr1nQv51OmTNGsWbO0evVqlShRQp06dVKzZs3UvXt3LVu2TNu3b9fLL7/s1XFH5g9hTqdTffv2VcWKFTVw4MC8mOVZmb+wzZs3m9jY2EuGr1u3znTs2NEkJyeb9PR006NHD/Phhx+aXbt2mVatWpnTp0+blJQU07FjRzNp0iRjjDG33367McaY2NhY8+233xpjjHn77bfNF198keX9C/8ePny4GTNmjDHGmB9//NE8+uijl9QSHh5u2rRpY9q1a2caNmxoHnnkETNjxgzjcrnM0aNHTVRUlDlx4oQxxpjZs2ebIUOGmLS0NNO0aVOza9cuY4wxI0eOdH/P2NhYd805jX/w4EHTtm1bY4wxycnJ5vnnnzcpKSnZfrcDBw6Y8PBwY4wxffr0Mf/5z3+MMcb89ttvplGjRiYpKclMmjTJdOjQwaSmppojR46Y2rVrm5MnT+a2u65YZo2nT582Dz74oNm4caMx5vy8PXDggNm6dasZPny4McYYp9NpYmNjzcqVK7N8tx49epi1a9caY4yZMGGCmT59utmzZ495/PHHTUpKijHGmDfeeMO89dZbl0z/9ttvN1FRUSYqKsrUq1fPREZGur//qFGjzKZNm4wx5+dZ7dq1jTHGvPnmm+af//ynMcaYRYsWmWHDhuW6v67GsGHDzJ133mnat29v4uPj3cvShfPNmKzrUGxsrBk8eLAxxpidO3eaRo0amdTUVDNo0CDzxBNPmLS0NHPo0CHTsGFDc/jwYTN27FgzcuRIY8z5ZbFZs2Zm165dZsGCBaZly5YmPT3dGGPMpEmT3MvshVwul2nevLn55ZdfjDHGLFu2zLz44ovGGJNj3/z555+mYcOG5tChQ8YYY/r3729Wr15tFixYYAYNGmSMMebDDz80zz33nMnIyDDJycmmffv25vPPPzebN2829957rzl16tQltWSOHxcXZ1asWGGMMWb69Olm4cKFHpezb7/91rRs2dKcOnXKpKenm7///e/m+++/N4MGDTLPPPOMcblcZvfu3aZ+/fqXzI/bb7/drF692hhjzOuvv25ef/11k5qaapo3b26ioqJMbGysqV27tuncuXOOfe1p/Vi/fr3p3bu3ycjIME6n07z44otm8eLFZv/+/aZXr17G6XQaY4wZMGCAeffdd911bd682Rhjchx/4cKF7vmxc+dO97Zw0KBBZsGCBZfUmfm9V69ebVq1amXOnTuXZfl74YUXzGeffWaMMSYxMdE0b97cnD592j3e0aNHTaNGjcyff/5pnE6n6dmzp7vPw8PDzTvvvGOMMWbmzJmmd+/expjzy3RcXJwxxphdu3aZJk2amNTUVK+X3WbNmpkjR44YY4wZM2aM2blzZ479cCUu3EZdqH379mb58uU5zvvLLXMLFizIsW9iY2PN5s2bc9xHHjhwwFSrVs3873//M8YY06tXLzNjxowc679wW2KMuWQdGzdunPnggw+MMcacPn3aREREmN9++8189NFHZvTo0cYYY1JTU01sbKz56quv8mCOXr0DBw6YGjVqmKioKNO6dWtTr1498+STT5oNGzYYY8xl9zfZzbs///zTvS9NT083//jHP8ygQYNMamqqCQ8Pd++TV6xYYWJiYowx5/vptddeM8YYM3nyZNOiRQuTnJxsDh48aOrWrXtJzQsWLDD33Xefez8VFRVlEhISPE7jSo8lLtze/lXt2bPH3HHHHWbixInuYXXq1DG7d+/OcZzNmzeb2rVrm6ioKNOuXTtz9913m0GDBhmXy3XZed2+fXuzatUqY4wx33zzjXnwwQdNampqttuXnLYJfyVXuk+6+LtfvK/M3Cd5c8x3oSvd91y4nL/wwgtm7dq15syZM6ZJkybmqaeeMsYYM3DgQLNu3TqvjzsmTZpk3nzzTTN48GD3Ou4LVp6527x5syIiIlS0aFFJ5y8jWbx4sdLS0hQeHu4+RRwREaFTp05lGbd58+bq1auXWrRooebNm6tRo0Y5Tuerr77SG2+8Ien8fVn//e9/s/1c5mUrq1at0pgxY/TQQw/J4XDo22+/1aFDh9S1a1dJksvlUunSpbVnzx6FhoaqevXqkqQOHTpkuZzm7rvvlqQcxy9XrpyCg4PVqVMnhYeHq3///goODs72u114/fPmzZs1atQoSdJNN92kWrVq6dtvv5V0/lKGoKAghYaG6rrrrtPp06fz/HI1T0qUKKGRI0e6T/Vnuu+++3Tddddp1qxZ2rt3r/bv33/JPY1RUVFavny5wsPD9cknn2jmzJlavXq1fv31Vz366KOSzp+Vu/POO7OdduYlOi6XS6NHj1bfvn317rvvavDgwfriiy/073//W3v27HFPNyYmRk888YSef/55LVq0SC+++GKu++tqvPrqq3ruuee0ceNGbdy4UY8++qjeeOMNtWrV6rLjZc6LO+64Q2FhYdq9e7f7+wQGBqp8+fK65557tH37dm3evFmjR4+WJF1//fVq3ry5tm7dqhIlSujOO+9UQMDlNy8Oh0MPP/ywli1bpj59+mjJkiXuX6S3bNmSbd988803uueee1S+fHlJcp+JvvDeti1btuiRRx6Rv7+/ihYtqsjISCUkJKhZs2aqXLmy+1fW7LRp00Zz585VmzZt9Nlnn2n69OnuXw9zWs6++uorhYeHu9t9//333e01b95cDodDVatW1fHjx7OdZubZrapVq2rbtm3av3+/Dh8+rNTUVJUpU0ZBQUHZXtp6sZzWj4SEBH333XeKiYmRJKWkpOiGG25QdHS0Bg0apHnz5mnfvn3asWOHbr75Zvd4mWe+chq/ffv2mjBhghITE/Xggw96fZ9IixYt9Mknn2jChAlZLhPetGmT9u7d6763KSMjQwcOHHC/v23bNtWpU0flypWTJD388MP67LPPsrQrSbfddptWrVrlHp55mW/16tUVGhqqvXv3er3shoeH6/HHH1eLFi3UunVr3XHHHV59x6vlcDhUpEiRHOf9kSNHclzmJKlOnTqX7Zuc9pEPPPCAQkND3dvBqlWr6uTJk7mq/cJ1bNOmTUpJSXFf0pacnKyffvpJCQkJ2rVrlzZv3uwevnv37kt+US8omZdlulwujRkzRr/88ov7WOBy+5vs5t0333yjOnXquK/2iIyM1ObNm7V//36VKlXKvT9v06aNhg0bptOnT0uSmjZtKun8FQ+1atVS0aJFdeONN15yzJIpu8sy9+zZc9lpXOmxhA2+/vprhYSEKCEhQb169XKv8w6HQ9L5W2g6duwo6fylkplnhi6+LPOpp57S22+/rfDw8Bzn9W+//ebe99auXVulS5fW3r17s92+FMR90r6S233Svffee9n2MvdJ3hzzZedK9z2S9MADDyghIUF+fn6KjIzUihUrlJ6erm3btmnEiBEaMGCA18cdc+bM0enTpy97f/TVsjLcuVyuS4ZlZGTIz88v2/cu1K1bN4WHh+vzzz/XuHHj9N133+V42UFAQIB7QyBJv/zyiypXriw/v+yfU9O6dWt9+eWXGjJkiKZPny6n06l77rlH//rXvySdP8V/9uxZHT58+LJ1FilSRJJyHD8gIEDz5s3T1q1btWHDBnXq1EkzZ87M9rtFRka62zXGZJmOMUZOp1OSsmzQHQ7HJZ/NL40bN3af6s+0Zs0aTZo0SV27dlVMTIyOHz9+SX3NmzfXmDFj9NVXX6lChQoqV66cnE6n2rRpo7i4OEnn723K/L458fPzU4cOHdz3Ab3wwgsqVaqUwsPD1bZtW/eDJCpWrKgbbrhBn376qY4ePapatWrps88+y1V/Va5c+Yrm0bp165ScnKy2bdu674/JvKcgcweTOX8yMjKyjOvv7+/+2+VyuXd42Q2/3PKSuYx6EhMTo3/84x/q3Lmz9u/f776sOae+2bp1a5Z17tixY5e0efG6k5u66tevr5dffll79uxRSEhIlg1yTsvZxduBxMRE90Fz5ny78P2LZa5bmeuVy+VSWFiYwsLCNGfOHJ05c0bR0dGaM2eOOnXq5K5DOn9Ad+GlrtmtH06nU3//+9/1xBNPSJJOnTolf39//fDDD+rXr5+6deum1q1by8/PL0ufXridyW784sWL65NPPtEXX3yhzz//XP/5z3+0YsWKy87fTHFxcYqMjMxyuZ/L5dIHH3zgHnb48GGFhoa6A5yn7XdO8/pqlt24uDj9+OOPWr9+vQYMGKBevXrl6oFaVyItLU379u3Tbbfdps2bN2c77+fPn5/jMidJt9xyy2X7Jqd9pHT12/oL55/L5dK4ceNUo0YNSecvfypdurQWLFigAQMGuLdHx44dU/HixXM1nfzg5+engQMH6uGHH9a7776rp59++rL7m+zm3cXzMHObml0fXLgcBgYGXjJObnmaxpUeS/zV/fzzz5o8ebLmzJmjIUOGaNq0aerdu7fuuusuff3116pataqCgoLcP+p26dJF6enpl7RTokQJtWnTRps2bdIDDzxwyfvGGHeQvni40+nMdvviKeD81eRmn3TixIks60pGRkaWZT9zefXmmC8nudn3XHjvY9OmTfXee+/J399fDRs21N69ezV//nzdfvvtCg4OztVxR506dXTnnXdq1KhRefagpov9pZ+WmZMGDRpo+fLlSklJUUZGhhYsWKAGDRqoYcOGWr9+vc6cOaO0tDR9+umnlxwIdOzYUWfPnnVf175z505J5w8QLj4Qrlu3rpYvXy7pfLB7+umnL3sQJ52/4X379u1at26datWqpR07dmjfvn2SpKlTpyo+Pl5VqlTRqVOn3GdNPv7442zbymn8nTt3KjY2Vvfdd58GDRqkW2+9Vfv27cvxu1043+bPny9JOnDggL7++uss154XFoMHD9bGjRt1+PBhSed/BWrTpo3at2+vUqVKacuWLZeEtKCgIDVp0kSjR49WVFSUpPMH8qtXr9bRo0dljNHw4cO9evJVQkKC+9fZL7/8Un369FGLFi20YcMGSXJPu3379ho1apR7erntrytVpEgRjR8/3v0LoDFGu3btcp91CAkJ0c8//yxJl/xylHkA+P333+vUqVO6/fbbJUmffPKJjDH6/fff9d133+nee+/NsrwcO3ZMa9asyfZBGtmtO5luuOEGVahQQZMmTVJUVJR7/cmpb+666y7t2LFDSUlJkqTRo0drzZo1WabRoEEDLV68WE6nU+fOndPHH3+s+vXrezXvMu8/GjZsmNq2bZvlvZyWs7p162r9+vU6e/asMjIy1K9fP6/OtOWkSpUqOnv2rPueyRUrVqhUqVKKj4/Xzz//rObNm2vJkiVasmRJtg/QuHj9aNCggZYsWeKur2fPnlq1apW++uor1atXT48//rhuueUWrVu3LtsfN3Ia/8MPP9TkyZPVpk0bvfLKKzp27JjOnDkjf39/jz+ShISEaPjw4e77mTOnk/kQkZ9//lmRkZE6d+6c+/177rlH33//vQ4fPixjjFasWOFxeyv93/Yz857RSpUqebXsZmRkqFWrVgoJCdEzzzyj6Ohonz/owOVyafLkyapVq5ZuvvnmHOe9p2Uup77JlNM+Mq81aNDA/aTTw4cPKyoqSocOHVKDBg00d+5cpaen6+zZs+rcubN27NiR59PPCwEBARo4cKCmTp2qpKQkr/Y3F7r33nu1Y8cOJSYmyuVyubexVapU0YkTJ/Tdd99JOr+e33DDDV7f3+gNb6eR233T5bbphV1qaqr69u2rAQMG6KabbtKYMWP04YcfaseOHerdu7feeust9xVLkvTjjz/qwIEDWX4kypT5g+Odd96Z47y+4YYbVLFiRX366aeSzt+Xd+TIEVWtWjXb7UtAQMBfdt7mxNt9UqlSpXTixAkdO3ZMaWlp+uKLL7JtL7fr4IVys++5cDm//vrrVaRIEX3++efu45+pU6cqPDzc3Ya3xx3Vq1fX008/rZ9++sl9f2Fe+8ufucu8VCdTZGSkRowYoV27dql9+/bKyMhQ48aNFRsbq4CAAHXt2lWPPfaYihUrppCQkEsuMXjxxRc1ePBgBQQEqFixYu7LFJs3b67o6Ogsl3/16dNHcXFxioqKUkBAgOLj4z0ebISGhurpp59WfHy8li5dqtGjR+uFF16Qy+VSuXLlNG7cOAUFBSk+Pl6DBg2Sn5+fKleunO0Zh7CwsGzHDwkJUe3atdWuXTsVLVpU99xzj5o2baqiRYtm+90yDR06VMOGDXN/x1GjRqls2bK565B8kHmqP/NRzx07dlT//v21fPlyBQYG6p577sn20obo6GgtXbpUrVu3lnR+BevVq5f+/ve/y+Vy6Y477lD37t2znWbmr/UOh0MlS5bUiBEjJJ2/0bdz584KDg5W9erVdeONN+rgwYOqVKmSWrVqpZdfftk9bm7760o1aNBAvXr1Uo8ePdy/NjZp0sR9aVafPn00cuRITZkyRY0bN84y7oEDB9z/imDixInuHVpKSorat2+vtLQ0jRgxQiEhIerZs6eGDx+uyMhIOZ1O9ejRQzVq1HD/KJEp88CgTJky2T56uH379ho4cKBWr17tHpZT3wQHB2vo0KF68skn5XK5VLt2bcXExOi3337TlClT9MYbb+j555/X/v37FR0drfT0dEVGRqply5ZePxK/TZs2+n/t3VtIVF0bB/D/dg6VqU12oNRGQsVK0wwzEQ84IgylpOGpw0CJFsVoCU5lDimNTKR5GLzoKiq0RkIGxYuozLKutINhXhSdKIlIRcmLmdBR3wtxf/mlftZrnzn+f3fu2Xuv5XbvWfO4nnlWY2PjTyWVp7vPUlNTcfDgQWRkZGB0dBTx8fGIiIiYlIbyK+RyObRaLSoqKpCYmAgXFxeYTCY0NDQgLy8P9fX1M6ZG/ffzoVKp8OrVK6SlpWFkZARRUVFITk5GT08PtFqtOHsfGBg45XMz3fETBVUSExMhkUig0+ng5uaGiIgIVFRUwNXVFWq1etp+TqQiTQz4er0e586dE/tTWlo6qcqau7s79Ho9MjMzIZfL4eXlNavUcKvViqSkJDg5OaG8vBwymWxW965UKkVubi4yMzOxZMkSrFq16o9UI+zp6RHfIybu9YkUsOmuvSAIM95zSUlJU/5tJsTGxk45Rk6UfJ8rWq0WxcXFYhEVnU4HpVKJjIwMfPz4EcnJybDb7di7d++s/wEzH6KjoxESEgKTyQSNRjOr8WbC6tWrodfrcejQISxbtkysqiiXy1FZWQmDwQCbzYYVK1agsrJyTvs92zZ+dWzq7u4W329nKvT0NzIajfDz8xOfOU9PTxQUFECn06GhoQGVlZWoqqpCX18frFYr1q9fj9OnTyM0NBRtbW3o6urCnj17IAgC7HY7/P39kZ2dPeO1LisrQ3FxMaqrqyGTyVBdXQ25XD7l+4ubmxs8PDyg0WgcYpYUmP2YJAgCsrKykJKSgnXr1mHr1q1Tnm+2n/mmM9uxJygoaNJ9Hh0djdbWVixfvhzh4eEwGo3ijG16evovfe6Qy+UoLi7GmTNnsHPnzjnPXBDG5iu/bh58+PABra2t4vd6jh07htTU1CnXxZhPo6OjuHTpErRaLZydnXH16lV8/fp1ztfGoT9nbGwMjx49gtlsFlNd/nY/VtL70UQFvon8eKL5MDAwgJqaGmi1Wjg5OaGkpESs+kdERETjFvzM3a/w9PTEy5cvkZCQAEEQEBkZKU6p/k2cnJygUCiQkpICmUwGT0/POVmfiP5/jEYjHjx4sCDWECRaCBQKBQYHB5GQkACJRIKAgACx4A4RERGNW1Qzd0RERERERI7KIQuqEBERERERLTYM7oiIiIiIiBwAgzsiIiIiIiIHwOCOiIgcwvDwMCIjI5GVlSVua2trQ0JCwpy1cf/+fXEZmYcPH8JkMgEALBYLjh49OmftEBER/Y5FVS2TiIgc171797Bp0yZ0dXXh3bt38PHxmfM24uLiEBcXB2B8YfRv377NeRtERES/i8EdERE5BLPZjF27dkGpVOL69es4f/78pNf7+/tRUFCAT58+QaFQYM2aNfDz80NOTg6ePn2K0tJS2Gw2yGQynDx5EtHR0bBYLKivr4fNZoOLiwuSk5Nx584dHD9+HHV1dRgZGYGrqyu8vb3R29uLI0eO4MuXL5BIJCgvL4ePjw80Gg0CAgLw4sUL9Pf3Iy0tDX19fWhvb4fNZkNVVRX8/f1x9+5dXL58GYIgQCKR4NSpU9ixY8c8XU0iIlqImJZJREQL3tu3b9HR0QG1Wo2kpCQ0NjZiYGBg0j4lJSXw9fXF7du3YTKZ8Pz5cwDjC6Tn5uaisLAQTU1NuHjxInQ6Hbq7u8Vz19TUoKamRjxXcHAwMjIysGvXLuTl5QEAuru7xXOEhobiypUr4v6fP39GXV0dysrKUFZWhrCwMFgsFkRFRaG2thYAUFpaiqKiIlgsFpw4cQJtbW1/9JoREZHjYXBHREQLntlsRmxsLFauXImgoCB4eXnh1q1bk/ZpbW1Feno6AGDt2rVQq9UAgM7OTiiVSgQHBwMA/Pz8sH37drS3twMA/P394eLi8j/7EBQUBG9vbwDA5s2b0d/fL74WHx8PANiwYQMAICoqCgCgVCrF1M7du3dDq9WisLAQg4ODyM7O/r2LQUREixaDOyIiWtCsVisaGxvxc6VviQAAAc9JREFU7NkzqFQqqFQq9Pb2ora2Fna7XdxPKpVibGxM/NnJaXwIHBkZgSAIk845NjYmHuvs7Dyrfkil//mmgyAIk9qSy+WT9pXJZD8dn5eXh5s3byIwMBAWiwUHDhyYVbtEREQTGNwREdGC1tTUBIVCgcePH6OlpQUtLS1obm6G1WqdNHsWExOD+vp6AOOpmM3NzRAEAdu2bcP79+/R2dkJAHjz5g2ePHmCsLCwGduVSCSTgsd/w263Q6VSwWazYd++fSgqKsLr168xNDQ0J+cnIqLFgQVViIhoQTObzTh8+DAkEom4zc3NDRqNBteuXRO3FRQUQK/XIzExEQqFAh4eHli6dCnc3d1hMplgMBjw/ft3CIKACxcuYOPGjejo6Ji23fDwcOTn58NgMCAgIOBf/Q5SqRRnz55Ffn4+pFIpBEGA0Wj8acaPiIhoJsLYj3kjREREDurGjRvYsmULQkJCMDQ0hP379yMnJwcxMTHz3TUiIqI5wZk7IiJaFHx9fWEwGDA6Oorh4WGo1WoGdkRE5FA4c0dEREREROQAWFCFiIiIiIjIATC4IyIiIiIicgAM7oiIiIiIiBwAgzsiIiIiIiIHwOCOiIiIiIjIAfwDHog8LnHhY8gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(15,8)})\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "\n",
    "\n",
    "sns.barplot(algorithms,scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
